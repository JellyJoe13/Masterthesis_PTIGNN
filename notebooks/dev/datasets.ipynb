{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:09.287024Z",
     "end_time": "2024-03-04T20:16:11.114663Z"
    }
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "import logging\n",
    "import ssl\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "from multiprocess.pool import Pool\n",
    "from torch_geometric.data.data import BaseData\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from ptgnn.features.chiro.embedding_functions import embedConformerWithAllPaths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.116663Z",
     "end_time": "2024-03-04T20:16:11.258048Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from ptgnn.transform import PRE_TRANSFORM_MAPPING\n",
    "from ptgnn.masking import MASKING_MAPPING\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.257049Z",
     "end_time": "2024-03-04T20:16:11.271085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.273086Z",
     "end_time": "2024-03-04T20:16:11.289596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.288594Z",
     "end_time": "2024-03-04T20:16:11.319898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.317899Z",
     "end_time": "2024-03-04T20:16:11.488324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from ptgnn.dataset.utils_chienn import download_url_to_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.489324Z",
     "end_time": "2024-03-04T20:16:11.504324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from ptgnn.features.chienn.molecule3d import smiles_to_3d_mol\n",
    "from ptgnn.dataset.utils_chienn import get_chiro_data_from_mol"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:16:11.505324Z",
     "end_time": "2024-03-04T20:16:11.535790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class RSDataset(pyg.data.InMemoryDataset): # potentially change to inmemory dataset\n",
    "    \"\"\"\n",
    "    Dataset adapted from ChiENN/GraphGPS: https://github.com/gmum/ChiENN/blob/master/experiments/graphgps/dataset/rs_dataset.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str = \"src\",\n",
    "            single_conformer: bool = True,\n",
    "            mask_chiral_tags: bool = False,\n",
    "            split: str = \"train\",\n",
    "            graph_mode: str = \"edge\",\n",
    "            max_atoms: int = 100,\n",
    "            max_attempts: int = 100 # significantly decreased - 5000 is way too much!\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init of the RS dataset class\n",
    "\n",
    "        :param root: Path to which the dataset should be saved\n",
    "        \"\"\"\n",
    "        # link storage\n",
    "        self.link_storage = {\n",
    "            'train': 'https://figshare.com/ndownloader/files/30975694?private_link=e23be65a884ce7fc8543',\n",
    "            'val': 'https://figshare.com/ndownloader/files/30975703?private_link=e23be65a884ce7fc8543',\n",
    "            'test': 'https://figshare.com/ndownloader/files/30975679?private_link=e23be65a884ce7fc8543'\n",
    "        }\n",
    "\n",
    "        # set internal parameters\n",
    "        self.single_conformer = single_conformer\n",
    "        self.mask_chiral_tags = mask_chiral_tags\n",
    "        self.split = split\n",
    "        self.graph_mode = graph_mode\n",
    "        self.pre_transform = PRE_TRANSFORM_MAPPING.get(self.graph_mode)\n",
    "        self.masking = MASKING_MAPPING.get(self.graph_mode)\n",
    "        self.max_atoms = max_atoms\n",
    "        self.max_attempts = max_attempts\n",
    "\n",
    "        super().__init__(\n",
    "            root=root,\n",
    "            transform=None,\n",
    "            pre_transform=self.pre_transform,\n",
    "            pre_filter=None\n",
    "        )\n",
    "        self.dataframe = pd.read_csv(os.path.join(self.processed_dir, f'{split}.csv'))\n",
    "        self.data, self.slices = torch.load(os.path.join(self.processed_dir, f\"{split}.pt\"))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = super().__getitem__(item)\n",
    "        if self.mask_chiral_tags:\n",
    "            data = self.masking(data)\n",
    "        return data\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.pickle', 'val.pickle', 'test.pickle']\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        name = 'single_conformer' if self.single_conformer else 'all_conformers'\n",
    "        graph_mode = self.graph_mode if self.graph_mode else ''\n",
    "        return os.path.join(self.root, name, graph_mode, 'processed')\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['val.pt', 'val.csv']# ['train.pt', 'val.pt', 'test.pt', 'train.csv', 'val.csv', 'test.csv']\n",
    "\n",
    "    def download(self):\n",
    "        for split, link in self.link_storage.items():\n",
    "            split_pickle_path = os.path.join(self.raw_dir, f'{split}.pickle')\n",
    "            download_url_to_path(link, split_pickle_path)\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Processes and saves datapoints from the entire dataset. It additionally saves original dataframes from\n",
    "        downloaded pickles which are then used in `SingleConformerBatchSampler` in `get_custom_loader`.\n",
    "        \"\"\"\n",
    "        for split in ['val']:# ['train', 'val', 'test']:\n",
    "            with open(os.path.join(self.raw_dir, f'{split}.pickle'), 'rb') as f:\n",
    "                split_df = pickle.load(f)\n",
    "\n",
    "            if self.single_conformer:\n",
    "                split_df = split_df.drop_duplicates(subset='ID')\n",
    "\n",
    "            data_list = []\n",
    "            omitted = 0\n",
    "            to_remove = set()\n",
    "            for index, row in tqdm(split_df.iterrows(), desc=f'Processing {split} dataset', total=len(split_df)):\n",
    "                smiles_nonstereo = row['SMILES_nostereo']\n",
    "                if smiles_nonstereo in to_remove:\n",
    "                    omitted += 1\n",
    "                    continue\n",
    "\n",
    "                smiles = row['ID']\n",
    "                mol = smiles_to_3d_mol(smiles, max_number_of_atoms=self.max_atoms, max_number_of_attempts=self.max_attempts)\n",
    "                if mol is None:\n",
    "                    omitted += 1\n",
    "                    to_remove.add(smiles_nonstereo)\n",
    "                    continue\n",
    "                try:\n",
    "                    data = get_chiro_data_from_mol(mol)\n",
    "                except Exception as e:\n",
    "                    omitted += 1\n",
    "                    to_remove.add(smiles_nonstereo)\n",
    "                    continue\n",
    "\n",
    "                if self.pre_transform is not None:\n",
    "                    data = self.pre_transform(data)\n",
    "\n",
    "                data.y = torch.tensor(row['RS_label_binary']).long()\n",
    "                data_list.append(data)\n",
    "\n",
    "            torch.save(self.collate(data_list),\n",
    "                       os.path.join(self.processed_dir, f'{split}.pt'))\n",
    "            split_df = split_df.drop(columns='rdkit_mol_cistrans_stereo')\n",
    "            split_df = split_df[~split_df['SMILES_nostereo'].isin(to_remove)]\n",
    "            split_df.to_csv(os.path.join(self.processed_dir, f'{split}.csv'), index=None)\n",
    "\n",
    "    def len(self) -> int:\n",
    "        return super().__len__()\n",
    "\n",
    "    def get(self, idx: int) -> BaseData:\n",
    "        return super().__getitem__(idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:26:16.632327Z",
     "end_time": "2024-03-04T17:26:16.657046Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data = RSDataset(split=\"val\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:26:24.509676Z",
     "end_time": "2024-03-04T17:28:41.643879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T17:10:05.045464Z",
     "end_time": "2024-03-04T17:10:05.069667Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch_geometric as pyg\n",
    "import torch\n",
    "import os\n",
    "from typing import Union, List, Tuple"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T19:44:07.104749Z",
     "end_time": "2024-03-04T19:44:07.134707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class Test(pyg.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str = \"src\",\n",
    "            single_conformer: bool = True,\n",
    "            mask_chiral_tags: bool = False,\n",
    "            split: str = \"train\",\n",
    "            graph_mode: str = \"edge\",\n",
    "            max_atoms: int = 100,\n",
    "            max_attempts: int = 100 # significantly decreased - 5000 is way too much!\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init of the RS dataset class\n",
    "\n",
    "        :param root: Path to which the dataset should be saved\n",
    "        \"\"\"\n",
    "        # link storage\n",
    "        self.link_storage = {\n",
    "            'train': 'https://figshare.com/ndownloader/files/30975694?private_link=e23be65a884ce7fc8543',\n",
    "            'val': 'https://figshare.com/ndownloader/files/30975703?private_link=e23be65a884ce7fc8543',\n",
    "            'test': 'https://figshare.com/ndownloader/files/30975679?private_link=e23be65a884ce7fc8543'\n",
    "        }\n",
    "\n",
    "        # set internal parameters\n",
    "        self.single_conformer = single_conformer\n",
    "        self.mask_chiral_tags = mask_chiral_tags\n",
    "        self.split = split\n",
    "        self.graph_mode = graph_mode\n",
    "        self.pre_transform = PRE_TRANSFORM_MAPPING.get(self.graph_mode)\n",
    "        self.masking = MASKING_MAPPING.get(self.graph_mode)\n",
    "        self.max_atoms = max_atoms\n",
    "        self.max_attempts = max_attempts\n",
    "\n",
    "        super().__init__(\n",
    "            root=root,\n",
    "            transform=None,\n",
    "            pre_transform=self.pre_transform,\n",
    "            pre_filter=None\n",
    "        )\n",
    "\n",
    "        self.data, self.slices = torch.load(os.path.join(self.processed_dir, f\"{split}.pt\"))\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.split}.pickle']\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        name = 'single_conformer' if self.single_conformer else 'all_conformers'\n",
    "        graph_mode = self.graph_mode if self.graph_mode else ''\n",
    "        return os.path.join(self.root, name, graph_mode, 'processed')\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{self.split}.pt', f'{self.split}.csv']\n",
    "\n",
    "    def download(self):\n",
    "        for split, link in self.link_storage.items():\n",
    "            split_pickle_path = os.path.join(self.raw_dir, f'{split}.pickle')\n",
    "            download_url_to_path(link, split_pickle_path)\n",
    "\n",
    "    def process(self):\n",
    "        # load downloaded data\n",
    "        with open(os.path.join(self.raw_dir, f'{self.split}.pickle'), 'rb') as f:\n",
    "            split_df = pickle.load(f)\n",
    "\n",
    "        if self.single_conformer:\n",
    "            split_df = split_df.drop_duplicates(subset=\"ID\")\n",
    "\n",
    "        data_list = []\n",
    "        to_remove = set()\n",
    "\n",
    "        # iterate over dataframe\n",
    "        for index, row in tqdm(\n",
    "                split_df.iterrows(),\n",
    "                desc=f\"Processing {self.split} dataset\",\n",
    "                total=len(split_df)\n",
    "        ):\n",
    "\n",
    "            # get nonstereo smiles string\n",
    "            smiles_nonstereo = row[\"SMILES_nostereo\"]\n",
    "\n",
    "            # check if need to be skipped because in list\n",
    "            if smiles_nonstereo in to_remove:\n",
    "                continue\n",
    "\n",
    "            # get the normal smiles\n",
    "            smiles = row['ID']\n",
    "            # get the molecule\n",
    "            mol = smiles_to_3d_mol(\n",
    "                smiles,\n",
    "                max_number_of_attempts=self.max_attempts,\n",
    "                max_number_of_atoms=self.max_atoms\n",
    "            )\n",
    "\n",
    "            # check if mol present\n",
    "            if mol is None:\n",
    "                to_remove.add(smiles_nonstereo)\n",
    "                continue\n",
    "\n",
    "            # attempt to generate data object (raw)\n",
    "            try:\n",
    "                data = get_chiro_data_from_mol(mol)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Omitting molecule {smiles} as cannot be properly embedded. The original error message was: {e}.\")\n",
    "                continue\n",
    "\n",
    "            # do transformation\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            # set label and append\n",
    "            data.y = torch.tensor(row['RS_label_binary']).long()\n",
    "            data_list.append(data)\n",
    "\n",
    "        # save processed data\n",
    "        torch.save(\n",
    "            self.collate(data_list),\n",
    "            os.path.join(self.processed_dir, f\"{self.split}.pt\")\n",
    "        )\n",
    "        split_df = split_df.drop(columns=\"rdkit_mol_cistrans_stereo\")\n",
    "        split_df[~split_df['SMILES_nostereo'].isin(to_remove)]\n",
    "        split_df.to_csv(os.path.join(self.processed_dir, f\"{self.split}.csv\"), index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:24:28.266535Z",
     "end_time": "2024-03-04T20:24:28.280533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class Test(pyg.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str = \"src\",\n",
    "            single_conformer: bool = True,\n",
    "            mask_chiral_tags: bool = False,\n",
    "            split: str = \"train\",\n",
    "            graph_mode: str = \"edge\",\n",
    "            max_atoms: int = 100,\n",
    "            max_attempts: int = 100 # significantly decreased - 5000 is way too much!\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Init of the RS dataset class\n",
    "\n",
    "        :param root: Path to which the dataset should be saved\n",
    "        \"\"\"\n",
    "        # link storage\n",
    "        self.link_storage = {\n",
    "            'train': 'https://figshare.com/ndownloader/files/30975694?private_link=e23be65a884ce7fc8543',\n",
    "            'val': 'https://figshare.com/ndownloader/files/30975703?private_link=e23be65a884ce7fc8543',\n",
    "            'test': 'https://figshare.com/ndownloader/files/30975679?private_link=e23be65a884ce7fc8543'\n",
    "        }\n",
    "\n",
    "        # set internal parameters\n",
    "        self.single_conformer = single_conformer\n",
    "        self.mask_chiral_tags = mask_chiral_tags\n",
    "        self.split = split\n",
    "        self.graph_mode = graph_mode\n",
    "        self.pre_transform = PRE_TRANSFORM_MAPPING.get(self.graph_mode)\n",
    "        self.masking = MASKING_MAPPING.get(self.graph_mode)\n",
    "        self.max_atoms = max_atoms\n",
    "        self.max_attempts = max_attempts\n",
    "\n",
    "        super().__init__(\n",
    "            root=root,\n",
    "            transform=None,\n",
    "            pre_transform=self.pre_transform,\n",
    "            pre_filter=None\n",
    "        )\n",
    "\n",
    "        self.data, self.slices = torch.load(os.path.join(self.processed_dir, f\"{split}.pt\"))\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.split}.pickle']\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        name = 'single_conformer' if self.single_conformer else 'all_conformers'\n",
    "        graph_mode = self.graph_mode if self.graph_mode else ''\n",
    "        return os.path.join(self.root, name, graph_mode, 'processed')\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{self.split}.pt', f'{self.split}.csv']\n",
    "\n",
    "    def download(self):\n",
    "        for split, link in self.link_storage.items():\n",
    "            split_pickle_path = os.path.join(self.raw_dir, f'{split}.pickle')\n",
    "            download_url_to_path(link, split_pickle_path)\n",
    "\n",
    "    def process(self):\n",
    "        # load downloaded data\n",
    "        with open(os.path.join(self.raw_dir, f'{self.split}.pickle'), 'rb') as f:\n",
    "            split_df = pickle.load(f)\n",
    "\n",
    "        if self.single_conformer:\n",
    "            split_df = split_df.drop_duplicates(subset=\"ID\")\n",
    "\n",
    "        # iterate over dataframe\n",
    "        def worker(entry):\n",
    "            from ptgnn.features.chienn.molecule3d import smiles_to_3d_mol\n",
    "            from ptgnn.dataset.utils_chienn import get_chiro_data_from_mol\n",
    "            import logging\n",
    "            import torch\n",
    "\n",
    "            index, row = entry\n",
    "\n",
    "            # get nonstereo smiles string\n",
    "            smiles_nonstereo = row[\"SMILES_nostereo\"]\n",
    "\n",
    "            # get the normal smiles\n",
    "            smiles = row['ID']\n",
    "            # get the molecule\n",
    "            mol = smiles_to_3d_mol(\n",
    "                smiles,\n",
    "                max_number_of_attempts=self.max_attempts,\n",
    "                max_number_of_atoms=self.max_atoms\n",
    "            )\n",
    "\n",
    "            # check if mol present\n",
    "            if mol is None:\n",
    "                return smiles_nonstereo, None\n",
    "\n",
    "            # attempt to generate data object (raw)\n",
    "            try:\n",
    "                data = get_chiro_data_from_mol(mol)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Omitting molecule {smiles} as cannot be properly embedded. The original error message was: {e}.\")\n",
    "                return smiles_nonstereo, None\n",
    "\n",
    "            # do transformation\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            # set label and append\n",
    "            data.y = torch.tensor(row['RS_label_binary']).long()\n",
    "\n",
    "            return smiles_nonstereo, data\n",
    "\n",
    "        with Pool(processes=os.cpu_count()) as p:\n",
    "            data_list = list(p.imap(worker, tqdm(split_df.iterrows())))\n",
    "\n",
    "        display(data_list)\n",
    "\n",
    "        # todo: seperate stuff and check for to_remove stuff\n",
    "        to_remove = set([\n",
    "            smiles_entry\n",
    "            for smiles_entry, indicator in data_list\n",
    "            if indicator is None\n",
    "        ])\n",
    "        display(to_remove)\n",
    "        data_list = [\n",
    "            data_object\n",
    "            for smiles, data_object in data_list\n",
    "            if data_object is not None and smiles not in to_remove\n",
    "        ]\n",
    "        display(data_list)\n",
    "\n",
    "        # save processed data\n",
    "        torch.save(\n",
    "            self.collate(data_list),\n",
    "            os.path.join(self.processed_dir, f\"{self.split}.pt\")\n",
    "        )\n",
    "        split_df = split_df.drop(columns=\"rdkit_mol_cistrans_stereo\")\n",
    "        split_df[~split_df['SMILES_nostereo'].isin(to_remove)]\n",
    "        split_df.to_csv(os.path.join(self.processed_dir, f\"{self.split}.csv\"), index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:37.099510Z",
     "end_time": "2024-03-04T20:37:37.114823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "t1 = Test(split='val')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:43.820218Z",
     "end_time": "2024-03-04T20:37:43.894495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[34, 52], edge_index=[2, 72], edge_attr=[72, 14], pos=[34, 3], bond_distances=[36], bond_distance_index=[2, 36], bond_angles=[60], bond_angle_index=[3, 60], dihedral_angles=[91], dihedral_angle_index=[4, 91], y=[1])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:43.998272Z",
     "end_time": "2024-03-04T20:37:44.006270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "Test(11740)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:44.158811Z",
     "end_time": "2024-03-04T20:37:44.168811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "11740"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:44.334525Z",
     "end_time": "2024-03-04T20:37:44.354523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "t2 = Test(split=\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:44.486038Z",
     "end_time": "2024-03-04T20:37:44.600553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[17, 52], edge_index=[2, 36], edge_attr=[36, 14], pos=[17, 3], bond_distances=[18], bond_distance_index=[2, 18], bond_angles=[34], bond_angle_index=[3, 34], dihedral_angles=[49], dihedral_angle_index=[4, 49], y=[1])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:46.682065Z",
     "end_time": "2024-03-04T20:37:46.707064Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "11677"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-04T20:37:51.058707Z",
     "end_time": "2024-03-04T20:37:51.081707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "34524it [03:09, 200.66it/s]"
     ]
    }
   ],
   "source": [
    "t3 = Test(split=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
