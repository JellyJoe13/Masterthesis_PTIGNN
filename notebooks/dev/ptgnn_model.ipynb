{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:19.411860Z",
     "end_time": "2024-03-13T16:33:23.071051Z"
    }
   },
   "outputs": [],
   "source": [
    "from ptgnn.runtime_config.run_config import fetch_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    'dataset' : {\n",
    "        'type' : \"rs\",\n",
    "        'mask_chiral_tags': True,\n",
    "        'transformation_mode': 'chienn_tree_basic',\n",
    "    },\n",
    "    'loader': {\n",
    "        'general': {\n",
    "            'n_neighbors_in_circle': 3,\n",
    "            'batch_size': 32,\n",
    "            'num_workers': 0,\n",
    "        },\n",
    "        'train': {},\n",
    "        'test': {},\n",
    "        'val': {}\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:23.073052Z",
     "end_time": "2024-03-13T16:33:23.087051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_loader, _, val_loader = fetch_loaders(data_config=data_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:23.088051Z",
     "end_time": "2024-03-13T16:33:27.469777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "DataBatch(x=[2356, 118], edge_index=[2, 6416], edge_attr=[6416, 80], pos=[2356, 6], y=[32], batch=[2356], ptr=[33], ptree=[2356])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    display(batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:27.467777Z",
     "end_time": "2024-03-13T16:33:27.526029Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model for one type (Z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# put through linear layers\n",
    "# todo: do so only for a  few and not for all as not all needed for this module"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:27.497030Z",
     "end_time": "2024-03-13T16:33:27.534444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "k = 3\n",
    "hidden_dim = 118"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:27.513031Z",
     "end_time": "2024-03-13T16:33:27.534444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:27.528436Z",
     "end_time": "2024-03-13T16:33:27.542544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "k_list = torch.nn.ModuleList([\n",
    "    torch.nn.Linear(118, hidden_dim)\n",
    "    for _ in range(k)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:13.904984Z",
     "end_time": "2024-03-12T19:37:13.926737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# put all elements through linear layers\n",
    "# todo add masking to only do to relevant layers\n",
    "elem_z_put_though = [\n",
    "    k_elem(batch.x)\n",
    "    for k_elem in k_list\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:13.919646Z",
     "end_time": "2024-03-12T19:37:13.940866Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[ 0.2861, -0.2076,  0.0117,  ...,  0.2689, -0.0708, -0.0571],\n         [ 0.0971, -0.0944, -0.0788,  ...,  0.1648,  0.0102, -0.0895],\n         [ 0.1436, -0.1071,  0.1052,  ...,  0.0311, -0.0337, -0.1437],\n         ...,\n         [ 0.3100, -0.0640, -0.0865,  ...,  0.2082, -0.0444, -0.0096],\n         [ 0.0092, -0.3440,  0.0048,  ...,  0.1946,  0.0930, -0.0004],\n         [ 0.3100, -0.0640, -0.0865,  ...,  0.2082, -0.0444, -0.0096]],\n        grad_fn=<AddmmBackward0>),\n tensor([[-0.0540,  0.1426, -0.0411,  ...,  0.0189, -0.0058,  0.3411],\n         [ 0.1692,  0.1748, -0.1855,  ...,  0.2441, -0.0910, -0.2534],\n         [ 0.1098,  0.0153, -0.1968,  ...,  0.1879, -0.0011, -0.0757],\n         ...,\n         [-0.1305,  0.3478,  0.0317,  ..., -0.1131,  0.0361,  0.1787],\n         [ 0.3895,  0.1442, -0.3329,  ...,  0.0253, -0.1248, -0.1514],\n         [-0.1305,  0.3478,  0.0317,  ..., -0.1131,  0.0361,  0.1787]],\n        grad_fn=<AddmmBackward0>),\n tensor([[ 0.0561,  0.2315,  0.1396,  ...,  0.1578,  0.0188,  0.0445],\n         [ 0.1429,  0.1755,  0.0855,  ...,  0.0728, -0.0118,  0.2019],\n         [ 0.0510,  0.2120,  0.1577,  ..., -0.0172,  0.0622,  0.2101],\n         ...,\n         [ 0.0442,  0.2362,  0.2971,  ...,  0.1448,  0.0370,  0.1643],\n         [ 0.0718,  0.1634, -0.1459,  ...,  0.0382,  0.0812,  0.1563],\n         [ 0.0442,  0.2362,  0.2971,  ...,  0.1448,  0.0370,  0.1643]],\n        grad_fn=<AddmmBackward0>)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem_z_put_though"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:13.936737Z",
     "end_time": "2024-03-12T19:37:13.980081Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:27.543547Z",
     "end_time": "2024-03-13T16:33:27.569055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# extract permutation trees from string\n",
    "permutation_trees = [\n",
    "    json.loads(p_string)\n",
    "    for p_string in batch.ptree\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:13.968080Z",
     "end_time": "2024-03-12T19:37:14.005592Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'P': [1]},\n {'P': [0, {'Z': [3, 7, 5]}]},\n {'P': [3, {'Z': [0, 5, 7]}]},\n {'P': [2, {'Z': [9]}]},\n {'P': [5, {'Z': [0, 7, 3]}]},\n {'P': [4, {'Z': [14, 19]}]},\n {'P': [7, {'Z': [0, 3, 5]}]},\n {'P': [6]},\n {'P': [9, {'Z': [2]}]},\n {'P': [8, {'Z': [11, 13]}]},\n {'P': [11, {'Z': [8, 13]}]},\n {'P': [10, {'Z': [15, 17]}]},\n {'P': [13, {'Z': [8, 11]}]},\n {'P': [12]},\n {'P': [15, {'Z': [10, 17]}]},\n {'P': [14, {'Z': [4, 19]}]},\n {'P': [17, {'Z': [10, 15]}]},\n {'P': [16]},\n {'P': [19, {'Z': [4, 14]}]},\n {'P': [18, {'Z': [21, 23, 25]}]},\n {'P': [21, {'Z': [18, 25, 23]}]},\n {'P': [20, {'Z': [27, 31, 29]}]},\n {'P': [23, {'Z': [18, 21, 25]}]},\n {'P': [22, {'Z': [26, 35, 33]}]},\n {'P': [25, {'Z': [18, 23, 21]}]},\n {'P': [24]},\n {'P': [27, {'Z': [20, 29, 31]}]},\n {'P': [26, {'Z': [22, 33, 35]}]},\n {'P': [29, {'Z': [20, 31, 27]}]},\n {'P': [28]},\n {'P': [31, {'Z': [20, 27, 29]}]},\n {'P': [30]},\n {'P': [33, {'Z': [22, 35, 26]}]},\n {'P': [32]},\n {'P': [35, {'Z': [22, 26, 33]}]},\n {'P': [34]},\n {'P': [37]},\n {'P': [36, {'Z': [39, 41, 43]}]},\n {'P': [39, {'Z': [36, 43, 41]}]},\n {'P': [38, {'Z': [45]}]},\n {'P': [41, {'Z': [36, 39, 43]}]},\n {'P': [40, {'Z': [50, 55]}]},\n {'P': [43, {'Z': [36, 41, 39]}]},\n {'P': [42]},\n {'P': [45, {'Z': [38]}]},\n {'P': [44, {'Z': [47, 49]}]},\n {'P': [47, {'Z': [44, 49]}]},\n {'P': [46, {'Z': [51, 53]}]},\n {'P': [49, {'Z': [44, 47]}]},\n {'P': [48]},\n {'P': [51, {'Z': [46, 53]}]},\n {'P': [50, {'Z': [40, 55]}]},\n {'P': [53, {'Z': [46, 51]}]},\n {'P': [52]},\n {'P': [55, {'Z': [40, 50]}]},\n {'P': [54, {'Z': [57, 59, 61]}]},\n {'P': [57, {'Z': [54, 61, 59]}]},\n {'P': [56, {'Z': [63, 67, 65]}]},\n {'P': [59, {'Z': [54, 57, 61]}]},\n {'P': [58, {'Z': [62, 71, 69]}]},\n {'P': [61, {'Z': [54, 59, 57]}]},\n {'P': [60]},\n {'P': [63, {'Z': [56, 65, 67]}]},\n {'P': [62, {'Z': [58, 69, 71]}]},\n {'P': [65, {'Z': [56, 67, 63]}]},\n {'P': [64]},\n {'P': [67, {'Z': [56, 63, 65]}]},\n {'P': [66]},\n {'P': [69, {'Z': [58, 71, 62]}]},\n {'P': [68]},\n {'P': [71, {'Z': [58, 62, 69]}]},\n {'P': [70]},\n {'P': [73]},\n {'P': [72, {'Z': [75, 79, 77]}]},\n {'P': [75, {'Z': [72, 77, 79]}]},\n {'P': [74, {'Z': [81, 83]}]},\n {'P': [77, {'Z': [72, 79, 75]}]},\n {'P': [76]},\n {'P': [79, {'Z': [72, 75, 77]}]},\n {'P': [78]},\n {'P': [81, {'Z': [74, 83]}]},\n {'P': [80, {'Z': [85, 87]}]},\n {'P': [83, {'Z': [74, 81]}]},\n {'P': [82, {'Z': [206, 213, 215]}]},\n {'P': [85, {'Z': [80, 87]}]},\n {'P': [84, {'Z': [89, 93, 91]}]},\n {'P': [87, {'Z': [80, 85]}]},\n {'P': [86]},\n {'P': [89, {'Z': [84, 91, 93]}]},\n {'P': [88, {'Z': [95, 97, 99]}]},\n {'P': [91, {'Z': [84, 93, 89]}]},\n {'P': [90]},\n {'P': [93, {'Z': [84, 89, 91]}]},\n {'P': [92]},\n {'P': [95, {'Z': [88, 99, 97]}]},\n {'P': [94, {'Z': [101, 103]}]},\n {'P': [97, {'Z': [88, 95, 99]}]},\n {'P': [96, {'Z': [207, 211, 209]}]},\n {'P': [99, {'Z': [88, 97, 95]}]},\n {'P': [98]},\n {'P': [101, {'Z': [94, 103]}]},\n {'P': [100, {'Z': [105, 107]}]},\n {'P': [103, {'Z': [94, 101]}]},\n {'P': [102, {'Z': [116, 121]}]},\n {'P': [105, {'Z': [100, 107]}]},\n {'P': [104, {'Z': [109, 111]}]},\n {'P': [107, {'Z': [100, 105]}]},\n {'P': [106]},\n {'P': [109, {'Z': [104, 111]}]},\n {'P': [108, {'Z': [113, 115]}]},\n {'P': [111, {'Z': [104, 109]}]},\n {'P': [110]},\n {'P': [113, {'Z': [108, 115]}]},\n {'P': [112, {'Z': [117, 119]}]},\n {'P': [115, {'Z': [108, 113]}]},\n {'P': [114]},\n {'P': [117, {'Z': [112, 119]}]},\n {'P': [116, {'Z': [102, 121]}]},\n {'P': [119, {'Z': [112, 117]}]},\n {'P': [118]},\n {'P': [121, {'Z': [102, 116]}]},\n {'P': [120, {'Z': [123, 125]}]},\n {'P': [123, {'Z': [120, 125]}]},\n {'P': [122, {'Z': [127]}]},\n {'P': [125, {'Z': [120, 123]}]},\n {'P': [124, {'Z': [132]}]},\n {'P': [127, {'Z': [122]}]},\n {'P': [126, {'Z': [129]}]},\n {'P': [129, {'Z': [126]}]},\n {'P': [128, {'Z': [131, 133]}]},\n {'P': [131, {'Z': [128, 133]}]},\n {'P': [130, {'Z': [135, 139, 137]}]},\n {'P': [133, {'Z': [128, 131]}]},\n {'P': [132, {'Z': [124]}]},\n {'P': [135, {'Z': [130, 137, 139]}]},\n {'P': [134, {'Z': [141, 143]}]},\n {'P': [137, {'Z': [130, 139, 135]}]},\n {'P': [136, {'Z': [163, 165]}]},\n {'P': [139, {'Z': [130, 135, 137]}]},\n {'P': [138, {'Z': [185, 187]}]},\n {'P': [141, {'Z': [134, 143]}]},\n {'P': [140, {'Z': [145, 147]}]},\n {'P': [143, {'Z': [134, 141]}]},\n {'P': [142, {'Z': [156, 161]}]},\n {'P': [145, {'Z': [140, 147]}]},\n {'P': [144, {'Z': [149, 151]}]},\n {'P': [147, {'Z': [140, 145]}]},\n {'P': [146]},\n {'P': [149, {'Z': [144, 151]}]},\n {'P': [148, {'Z': [153, 155]}]},\n {'P': [151, {'Z': [144, 149]}]},\n {'P': [150]},\n {'P': [153, {'Z': [148, 155]}]},\n {'P': [152, {'Z': [157, 159]}]},\n {'P': [155, {'Z': [148, 153]}]},\n {'P': [154]},\n {'P': [157, {'Z': [152, 159]}]},\n {'P': [156, {'Z': [142, 161]}]},\n {'P': [159, {'Z': [152, 157]}]},\n {'P': [158]},\n {'P': [161, {'Z': [142, 156]}]},\n {'P': [160]},\n {'P': [163, {'Z': [136, 165]}]},\n {'P': [162, {'Z': [167, 169]}]},\n {'P': [165, {'Z': [136, 163]}]},\n {'P': [164, {'Z': [178, 183]}]},\n {'P': [167, {'Z': [162, 169]}]},\n {'P': [166, {'Z': [171, 173]}]},\n {'P': [169, {'Z': [162, 167]}]},\n {'P': [168]},\n {'P': [171, {'Z': [166, 173]}]},\n {'P': [170, {'Z': [175, 177]}]},\n {'P': [173, {'Z': [166, 171]}]},\n {'P': [172]},\n {'P': [175, {'Z': [170, 177]}]},\n {'P': [174, {'Z': [179, 181]}]},\n {'P': [177, {'Z': [170, 175]}]},\n {'P': [176]},\n {'P': [179, {'Z': [174, 181]}]},\n {'P': [178, {'Z': [164, 183]}]},\n {'P': [181, {'Z': [174, 179]}]},\n {'P': [180]},\n {'P': [183, {'Z': [164, 178]}]},\n {'P': [182]},\n {'P': [185, {'Z': [138, 187]}]},\n {'P': [184, {'Z': [189, 191]}]},\n {'P': [187, {'Z': [138, 185]}]},\n {'P': [186, {'Z': [200, 205]}]},\n {'P': [189, {'Z': [184, 191]}]},\n {'P': [188, {'Z': [193, 195]}]},\n {'P': [191, {'Z': [184, 189]}]},\n {'P': [190]},\n {'P': [193, {'Z': [188, 195]}]},\n {'P': [192, {'Z': [197, 199]}]},\n {'P': [195, {'Z': [188, 193]}]},\n {'P': [194]},\n {'P': [197, {'Z': [192, 199]}]},\n {'P': [196, {'Z': [201, 203]}]},\n {'P': [199, {'Z': [192, 197]}]},\n {'P': [198]},\n {'P': [201, {'Z': [196, 203]}]},\n {'P': [200, {'Z': [186, 205]}]},\n {'P': [203, {'Z': [196, 201]}]},\n {'P': [202]},\n {'P': [205, {'Z': [186, 200]}]},\n {'P': [204]},\n {'P': [207, {'Z': [96, 209, 211]}]},\n {'P': [206, {'Z': [82, 215, 213]}]},\n {'P': [209, {'Z': [96, 211, 207]}]},\n {'P': [208]},\n {'P': [211, {'Z': [96, 207, 209]}]},\n {'P': [210]},\n {'P': [213, {'Z': [82, 206, 215]}]},\n {'P': [212]},\n {'P': [215, {'Z': [82, 213, 206]}]},\n {'P': [214]},\n {'P': [217]},\n {'P': [216, {'Z': [219, 223, 221]}]},\n {'P': [219, {'Z': [216, 221, 223]}]},\n {'P': [218, {'Z': [225, 227]}]},\n {'P': [221, {'Z': [216, 223, 219]}]},\n {'P': [220]},\n {'P': [223, {'Z': [216, 219, 221]}]},\n {'P': [222]},\n {'P': [225, {'Z': [218, 227]}]},\n {'P': [224, {'Z': [229, 231]}]},\n {'P': [227, {'Z': [218, 225]}]},\n {'P': [226, {'Z': [350, 357, 359]}]},\n {'P': [229, {'Z': [224, 231]}]},\n {'P': [228, {'Z': [233, 237, 235]}]},\n {'P': [231, {'Z': [224, 229]}]},\n {'P': [230]},\n {'P': [233, {'Z': [228, 235, 237]}]},\n {'P': [232, {'Z': [239, 243, 241]}]},\n {'P': [235, {'Z': [228, 237, 233]}]},\n {'P': [234]},\n {'P': [237, {'Z': [228, 233, 235]}]},\n {'P': [236]},\n {'P': [239, {'Z': [232, 241, 243]}]},\n {'P': [238, {'Z': [245, 247]}]},\n {'P': [241, {'Z': [232, 243, 239]}]},\n {'P': [240, {'Z': [351, 355, 353]}]},\n {'P': [243, {'Z': [232, 239, 241]}]},\n {'P': [242]},\n {'P': [245, {'Z': [238, 247]}]},\n {'P': [244, {'Z': [249, 251]}]},\n {'P': [247, {'Z': [238, 245]}]},\n {'P': [246, {'Z': [260, 265]}]},\n {'P': [249, {'Z': [244, 251]}]},\n {'P': [248, {'Z': [253, 255]}]},\n {'P': [251, {'Z': [244, 249]}]},\n {'P': [250]},\n {'P': [253, {'Z': [248, 255]}]},\n {'P': [252, {'Z': [257, 259]}]},\n {'P': [255, {'Z': [248, 253]}]},\n {'P': [254]},\n {'P': [257, {'Z': [252, 259]}]},\n {'P': [256, {'Z': [261, 263]}]},\n {'P': [259, {'Z': [252, 257]}]},\n {'P': [258]},\n {'P': [261, {'Z': [256, 263]}]},\n {'P': [260, {'Z': [246, 265]}]},\n {'P': [263, {'Z': [256, 261]}]},\n {'P': [262]},\n {'P': [265, {'Z': [246, 260]}]},\n {'P': [264, {'Z': [267, 269]}]},\n {'P': [267, {'Z': [264, 269]}]},\n {'P': [266, {'Z': [271]}]},\n {'P': [269, {'Z': [264, 267]}]},\n {'P': [268, {'Z': [276]}]},\n {'P': [271, {'Z': [266]}]},\n {'P': [270, {'Z': [273]}]},\n {'P': [273, {'Z': [270]}]},\n {'P': [272, {'Z': [275, 277]}]},\n {'P': [275, {'Z': [272, 277]}]},\n {'P': [274, {'Z': [279, 283, 281]}]},\n {'P': [277, {'Z': [272, 275]}]},\n {'P': [276, {'Z': [268]}]},\n {'P': [279, {'Z': [274, 281, 283]}]},\n {'P': [278, {'Z': [285, 287]}]},\n {'P': [281, {'Z': [274, 283, 279]}]},\n {'P': [280, {'Z': [307, 309]}]},\n {'P': [283, {'Z': [274, 279, 281]}]},\n {'P': [282, {'Z': [329, 331]}]},\n {'P': [285, {'Z': [278, 287]}]},\n {'P': [284, {'Z': [289, 291]}]},\n {'P': [287, {'Z': [278, 285]}]},\n {'P': [286, {'Z': [300, 305]}]},\n {'P': [289, {'Z': [284, 291]}]},\n {'P': [288, {'Z': [293, 295]}]},\n {'P': [291, {'Z': [284, 289]}]},\n {'P': [290]},\n {'P': [293, {'Z': [288, 295]}]},\n {'P': [292, {'Z': [297, 299]}]},\n {'P': [295, {'Z': [288, 293]}]},\n {'P': [294]},\n {'P': [297, {'Z': [292, 299]}]},\n {'P': [296, {'Z': [301, 303]}]},\n {'P': [299, {'Z': [292, 297]}]},\n {'P': [298]},\n {'P': [301, {'Z': [296, 303]}]},\n {'P': [300, {'Z': [286, 305]}]},\n {'P': [303, {'Z': [296, 301]}]},\n {'P': [302]},\n {'P': [305, {'Z': [286, 300]}]},\n {'P': [304]},\n {'P': [307, {'Z': [280, 309]}]},\n {'P': [306, {'Z': [311, 313]}]},\n {'P': [309, {'Z': [280, 307]}]},\n {'P': [308, {'Z': [322, 327]}]},\n {'P': [311, {'Z': [306, 313]}]},\n {'P': [310, {'Z': [315, 317]}]},\n {'P': [313, {'Z': [306, 311]}]},\n {'P': [312]},\n {'P': [315, {'Z': [310, 317]}]},\n {'P': [314, {'Z': [319, 321]}]},\n {'P': [317, {'Z': [310, 315]}]},\n {'P': [316]},\n {'P': [319, {'Z': [314, 321]}]},\n {'P': [318, {'Z': [323, 325]}]},\n {'P': [321, {'Z': [314, 319]}]},\n {'P': [320]},\n {'P': [323, {'Z': [318, 325]}]},\n {'P': [322, {'Z': [308, 327]}]},\n {'P': [325, {'Z': [318, 323]}]},\n {'P': [324]},\n {'P': [327, {'Z': [308, 322]}]},\n {'P': [326]},\n {'P': [329, {'Z': [282, 331]}]},\n {'P': [328, {'Z': [333, 335]}]},\n {'P': [331, {'Z': [282, 329]}]},\n {'P': [330, {'Z': [344, 349]}]},\n {'P': [333, {'Z': [328, 335]}]},\n {'P': [332, {'Z': [337, 339]}]},\n {'P': [335, {'Z': [328, 333]}]},\n {'P': [334]},\n {'P': [337, {'Z': [332, 339]}]},\n {'P': [336, {'Z': [341, 343]}]},\n {'P': [339, {'Z': [332, 337]}]},\n {'P': [338]},\n {'P': [341, {'Z': [336, 343]}]},\n {'P': [340, {'Z': [345, 347]}]},\n {'P': [343, {'Z': [336, 341]}]},\n {'P': [342]},\n {'P': [345, {'Z': [340, 347]}]},\n {'P': [344, {'Z': [330, 349]}]},\n {'P': [347, {'Z': [340, 345]}]},\n {'P': [346]},\n {'P': [349, {'Z': [330, 344]}]},\n {'P': [348]},\n {'P': [351, {'Z': [240, 353, 355]}]},\n {'P': [350, {'Z': [226, 359, 357]}]},\n {'P': [353, {'Z': [240, 355, 351]}]},\n {'P': [352]},\n {'P': [355, {'Z': [240, 351, 353]}]},\n {'P': [354]},\n {'P': [357, {'Z': [226, 350, 359]}]},\n {'P': [356]},\n {'P': [359, {'Z': [226, 357, 350]}]},\n {'P': [358]},\n {'P': [361]},\n {'P': [360, {'Z': [363, 365]}]},\n {'P': [363, {'Z': [360, 365]}]},\n {'P': [362, {'Z': [367, 369]}]},\n {'P': [365, {'Z': [360, 363]}]},\n {'P': [364, {'Z': [450, 455]}]},\n {'P': [367, {'Z': [362, 369]}]},\n {'P': [366, {'Z': [371, 373]}]},\n {'P': [369, {'Z': [362, 367]}]},\n {'P': [368]},\n {'P': [371, {'Z': [366, 373]}]},\n {'P': [370, {'Z': [375, 377]}]},\n {'P': [373, {'Z': [366, 371]}]},\n {'P': [372]},\n {'P': [375, {'Z': [370, 377]}]},\n {'P': [374, {'Z': [379, 381, 383]}]},\n {'P': [377, {'Z': [370, 375]}]},\n {'P': [376, {'Z': [451, 453]}]},\n {'P': [379, {'Z': [374, 383, 381]}]},\n {'P': [378, {'Z': [385, 387]}]},\n {'P': [381, {'Z': [374, 379, 383]}]},\n {'P': [380]},\n {'P': [383, {'Z': [374, 381, 379]}]},\n {'P': [382]},\n {'P': [385, {'Z': [378, 387]}]},\n {'P': [384, {'Z': [389, 391, 393]}]},\n {'P': [387, {'Z': [378, 385]}]},\n {'P': [386, {'Z': [440, 449, 447]}]},\n {'P': [389, {'Z': [384, 393, 391]}]},\n {'P': [388, {'Z': [395, 397, 399]}]},\n {'P': [391, {'Z': [384, 389, 393]}]},\n {'P': [390]},\n {'P': [393, {'Z': [384, 391, 389]}]},\n {'P': [392]},\n {'P': [395, {'Z': [388, 399, 397]}]},\n {'P': [394, {'Z': [401, 403]}]},\n {'P': [397, {'Z': [388, 395, 399]}]},\n {'P': [396]},\n {'P': [399, {'Z': [388, 397, 395]}]},\n {'P': [398]},\n {'P': [401, {'Z': [394, 403]}]},\n {'P': [400, {'Z': [405, 409, 407]}]},\n {'P': [403, {'Z': [394, 401]}]},\n {'P': [402, {'Z': [441, 445, 443]}]},\n {'P': [405, {'Z': [400, 407, 409]}]},\n {'P': [404, {'Z': [411, 415, 413]}]},\n {'P': [407, {'Z': [400, 409, 405]}]},\n {'P': [406]},\n {'P': [409, {'Z': [400, 405, 407]}]},\n {'P': [408]},\n {'P': [411, {'Z': [404, 413, 415]}]},\n {'P': [410, {'Z': [417, 419, 421]}]},\n {'P': [413, {'Z': [404, 415, 411]}]},\n {'P': [412, {'Z': [430, 439, 437]}]},\n {'P': [415, {'Z': [404, 411, 413]}]},\n {'P': [414]},\n {'P': [417, {'Z': [410, 421, 419]}]},\n {'P': [416, {'Z': [423, 425]}]},\n {'P': [419, {'Z': [410, 417, 421]}]},\n {'P': [418]},\n {'P': [421, {'Z': [410, 419, 417]}]},\n {'P': [420]},\n {'P': [423, {'Z': [416, 425]}]},\n {'P': [422, {'Z': [427, 429]}]},\n {'P': [425, {'Z': [416, 423]}]},\n {'P': [424]},\n {'P': [427, {'Z': [422, 429]}]},\n {'P': [426, {'Z': [431, 435, 433]}]},\n {'P': [429, {'Z': [422, 427]}]},\n {'P': [428]},\n {'P': [431, {'Z': [426, 433, 435]}]},\n {'P': [430, {'Z': [412, 437, 439]}]},\n {'P': [433, {'Z': [426, 435, 431]}]},\n {'P': [432]},\n {'P': [435, {'Z': [426, 431, 433]}]},\n {'P': [434]},\n {'P': [437, {'Z': [412, 439, 430]}]},\n {'P': [436]},\n {'P': [439, {'Z': [412, 430, 437]}]},\n {'P': [438]},\n {'P': [441, {'Z': [402, 443, 445]}]},\n {'P': [440, {'Z': [386, 447, 449]}]},\n {'P': [443, {'Z': [402, 445, 441]}]},\n {'P': [442]},\n {'P': [445, {'Z': [402, 441, 443]}]},\n {'P': [444]},\n {'P': [447, {'Z': [386, 449, 440]}]},\n {'P': [446]},\n {'P': [449, {'Z': [386, 440, 447]}]},\n {'P': [448]},\n {'P': [451, {'Z': [376, 453]}]},\n {'P': [450, {'Z': [364, 455]}]},\n {'P': [453, {'Z': [376, 451]}]},\n {'P': [452]},\n {'P': [455, {'Z': [364, 450]}]},\n {'P': [454]},\n {'P': [457]},\n {'P': [456, {'Z': [459, 461]}]},\n {'P': [459, {'Z': [456, 461]}]},\n {'P': [458, {'Z': [463, 465]}]},\n {'P': [461, {'Z': [456, 459]}]},\n {'P': [460, {'Z': [546, 551]}]},\n {'P': [463, {'Z': [458, 465]}]},\n {'P': [462, {'Z': [467, 469]}]},\n {'P': [465, {'Z': [458, 463]}]},\n {'P': [464]},\n {'P': [467, {'Z': [462, 469]}]},\n {'P': [466, {'Z': [471, 473]}]},\n {'P': [469, {'Z': [462, 467]}]},\n {'P': [468]},\n {'P': [471, {'Z': [466, 473]}]},\n {'P': [470, {'Z': [475, 477, 479]}]},\n {'P': [473, {'Z': [466, 471]}]},\n {'P': [472, {'Z': [547, 549]}]},\n {'P': [475, {'Z': [470, 479, 477]}]},\n {'P': [474, {'Z': [481, 483]}]},\n {'P': [477, {'Z': [470, 475, 479]}]},\n {'P': [476]},\n {'P': [479, {'Z': [470, 477, 475]}]},\n {'P': [478]},\n {'P': [481, {'Z': [474, 483]}]},\n {'P': [480, {'Z': [485, 487, 489]}]},\n {'P': [483, {'Z': [474, 481]}]},\n {'P': [482, {'Z': [536, 545, 543]}]},\n {'P': [485, {'Z': [480, 489, 487]}]},\n {'P': [484, {'Z': [491, 493, 495]}]},\n {'P': [487, {'Z': [480, 485, 489]}]},\n {'P': [486]},\n {'P': [489, {'Z': [480, 487, 485]}]},\n {'P': [488]},\n {'P': [491, {'Z': [484, 495, 493]}]},\n {'P': [490, {'Z': [497, 499]}]},\n {'P': [493, {'Z': [484, 491, 495]}]},\n {'P': [492]},\n {'P': [495, {'Z': [484, 493, 491]}]},\n {'P': [494]},\n {'P': [497, {'Z': [490, 499]}]},\n {'P': [496, {'Z': [501, 503, 505]}]},\n {'P': [499, {'Z': [490, 497]}]},\n {'P': [498, {'Z': [537, 541, 539]}]},\n {'P': [501, {'Z': [496, 505, 503]}]},\n {'P': [500, {'Z': [507, 509, 511]}]},\n {'P': [503, {'Z': [496, 501, 505]}]},\n {'P': [502]},\n {'P': [505, {'Z': [496, 503, 501]}]},\n {'P': [504]},\n {'P': [507, {'Z': [500, 511, 509]}]},\n {'P': [506, {'Z': [513, 517, 515]}]},\n {'P': [509, {'Z': [500, 507, 511]}]},\n {'P': [508, {'Z': [526, 535, 533]}]},\n {'P': [511, {'Z': [500, 509, 507]}]},\n {'P': [510]},\n {'P': [513, {'Z': [506, 515, 517]}]},\n {'P': [512, {'Z': [519, 521]}]},\n {'P': [515, {'Z': [506, 517, 513]}]},\n {'P': [514]},\n {'P': [517, {'Z': [506, 513, 515]}]},\n {'P': [516]},\n {'P': [519, {'Z': [512, 521]}]},\n {'P': [518, {'Z': [523, 525]}]},\n {'P': [521, {'Z': [512, 519]}]},\n {'P': [520]},\n {'P': [523, {'Z': [518, 525]}]},\n {'P': [522, {'Z': [527, 531, 529]}]},\n {'P': [525, {'Z': [518, 523]}]},\n {'P': [524]},\n {'P': [527, {'Z': [522, 529, 531]}]},\n {'P': [526, {'Z': [508, 533, 535]}]},\n {'P': [529, {'Z': [522, 531, 527]}]},\n {'P': [528]},\n {'P': [531, {'Z': [522, 527, 529]}]},\n {'P': [530]},\n {'P': [533, {'Z': [508, 535, 526]}]},\n {'P': [532]},\n {'P': [535, {'Z': [508, 526, 533]}]},\n {'P': [534]},\n {'P': [537, {'Z': [498, 539, 541]}]},\n {'P': [536, {'Z': [482, 543, 545]}]},\n {'P': [539, {'Z': [498, 541, 537]}]},\n {'P': [538]},\n {'P': [541, {'Z': [498, 537, 539]}]},\n {'P': [540]},\n {'P': [543, {'Z': [482, 545, 536]}]},\n {'P': [542]},\n {'P': [545, {'Z': [482, 536, 543]}]},\n {'P': [544]},\n {'P': [547, {'Z': [472, 549]}]},\n {'P': [546, {'Z': [460, 551]}]},\n {'P': [549, {'Z': [472, 547]}]},\n {'P': [548]},\n {'P': [551, {'Z': [460, 546]}]},\n {'P': [550]},\n {'P': [553]},\n {'P': [552, {'Z': [555, 557]}]},\n {'P': [555, {'Z': [552, 557]}]},\n {'P': [554, {'Z': [559, 561]}]},\n {'P': [557, {'Z': [552, 555]}]},\n {'P': [556, {'Z': [570, 611]}]},\n {'P': [559, {'Z': [554, 561]}]},\n {'P': [558, {'Z': [563, 565]}]},\n {'P': [561, {'Z': [554, 559]}]},\n {'P': [560]},\n {'P': [563, {'Z': [558, 565]}]},\n {'P': [562, {'Z': [567]}]},\n {'P': [565, {'Z': [558, 563]}]},\n {'P': [564]},\n {'P': [567, {'Z': [562]}]},\n {'P': [566, {'Z': [569, 571]}]},\n {'P': [569, {'Z': [566, 571]}]},\n {'P': [568, {'Z': [573, 577, 575]}]},\n {'P': [571, {'Z': [566, 569]}]},\n {'P': [570, {'Z': [556, 611]}]},\n {'P': [573, {'Z': [568, 575, 577]}]},\n {'P': [572, {'Z': [579]}]},\n {'P': [575, {'Z': [568, 577, 573]}]},\n {'P': [574]},\n {'P': [577, {'Z': [568, 573, 575]}]},\n {'P': [576]},\n {'P': [579, {'Z': [572]}]},\n {'P': [578, {'Z': [581, 585, 583]}]},\n {'P': [581, {'Z': [578, 583, 585]}]},\n {'P': [580, {'Z': [587, 589, 591]}]},\n {'P': [583, {'Z': [578, 585, 581]}]},\n {'P': [582, {'Z': [604]}]},\n {'P': [585, {'Z': [578, 581, 583]}]},\n {'P': [584]},\n {'P': [587, {'Z': [580, 591, 589]}]},\n {'P': [586, {'Z': [593, 595, 597]}]},\n {'P': [589, {'Z': [580, 587, 591]}]},\n {'P': [588]},\n {'P': [591, {'Z': [580, 589, 587]}]},\n {'P': [590]},\n {'P': [593, {'Z': [586, 597, 595]}]},\n {'P': [592, {'Z': [599, 601, 603]}]},\n {'P': [595, {'Z': [586, 593, 597]}]},\n {'P': [594]},\n {'P': [597, {'Z': [586, 595, 593]}]},\n {'P': [596]},\n {'P': [599, {'Z': [592, 603, 601]}]},\n {'P': [598, {'Z': [605, 607, 609]}]},\n {'P': [601, {'Z': [592, 599, 603]}]},\n {'P': [600]},\n {'P': [603, {'Z': [592, 601, 599]}]},\n {'P': [602]},\n {'P': [605, {'Z': [598, 609, 607]}]},\n {'P': [604, {'Z': [582]}]},\n {'P': [607, {'Z': [598, 605, 609]}]},\n {'P': [606]},\n {'P': [609, {'Z': [598, 607, 605]}]},\n {'P': [608]},\n {'P': [611, {'Z': [556, 570]}]},\n {'P': [610]},\n {'P': [613]},\n {'P': [612, {'Z': [615, 617]}]},\n {'P': [615, {'Z': [612, 617]}]},\n {'P': [614, {'Z': [619, 621]}]},\n {'P': [617, {'Z': [612, 615]}]},\n {'P': [616, {'Z': [630, 671]}]},\n {'P': [619, {'Z': [614, 621]}]},\n {'P': [618, {'Z': [623, 625]}]},\n {'P': [621, {'Z': [614, 619]}]},\n {'P': [620]},\n {'P': [623, {'Z': [618, 625]}]},\n {'P': [622, {'Z': [627]}]},\n {'P': [625, {'Z': [618, 623]}]},\n {'P': [624]},\n {'P': [627, {'Z': [622]}]},\n {'P': [626, {'Z': [629, 631]}]},\n {'P': [629, {'Z': [626, 631]}]},\n {'P': [628, {'Z': [633, 637, 635]}]},\n {'P': [631, {'Z': [626, 629]}]},\n {'P': [630, {'Z': [616, 671]}]},\n {'P': [633, {'Z': [628, 635, 637]}]},\n {'P': [632, {'Z': [639]}]},\n {'P': [635, {'Z': [628, 637, 633]}]},\n {'P': [634]},\n {'P': [637, {'Z': [628, 633, 635]}]},\n {'P': [636]},\n {'P': [639, {'Z': [632]}]},\n {'P': [638, {'Z': [641, 643, 645]}]},\n {'P': [641, {'Z': [638, 645, 643]}]},\n {'P': [640, {'Z': [647, 651, 649]}]},\n {'P': [643, {'Z': [638, 641, 645]}]},\n {'P': [642, {'Z': [664]}]},\n {'P': [645, {'Z': [638, 643, 641]}]},\n {'P': [644]},\n {'P': [647, {'Z': [640, 649, 651]}]},\n {'P': [646, {'Z': [653, 655, 657]}]},\n {'P': [649, {'Z': [640, 651, 647]}]},\n {'P': [648]},\n {'P': [651, {'Z': [640, 647, 649]}]},\n {'P': [650]},\n {'P': [653, {'Z': [646, 657, 655]}]},\n {'P': [652, {'Z': [659, 661, 663]}]},\n {'P': [655, {'Z': [646, 653, 657]}]},\n {'P': [654]},\n {'P': [657, {'Z': [646, 655, 653]}]},\n {'P': [656]},\n {'P': [659, {'Z': [652, 663, 661]}]},\n {'P': [658, {'Z': [665, 669, 667]}]},\n {'P': [661, {'Z': [652, 659, 663]}]},\n {'P': [660]},\n {'P': [663, {'Z': [652, 661, 659]}]},\n {'P': [662]},\n {'P': [665, {'Z': [658, 667, 669]}]},\n {'P': [664, {'Z': [642]}]},\n {'P': [667, {'Z': [658, 669, 665]}]},\n {'P': [666]},\n {'P': [669, {'Z': [658, 665, 667]}]},\n {'P': [668]},\n {'P': [671, {'Z': [616, 630]}]},\n {'P': [670]},\n {'P': [673, {'Z': [675]}]},\n {'P': [672, {'Z': [677]}]},\n {'P': [675, {'Z': [673]}]},\n {'P': [674]},\n {'P': [677, {'Z': [672]}]},\n {'P': [676, {'Z': [679]}]},\n {'P': [679, {'Z': [676]}]},\n {'P': [678, {'Z': [681]}]},\n {'P': [681, {'Z': [678]}]},\n {'P': [680, {'Z': [683]}]},\n {'P': [683, {'Z': [680]}]},\n {'P': [682, {'Z': [685]}]},\n {'P': [685, {'Z': [682]}]},\n {'P': [684, {'Z': [687]}]},\n {'P': [687, {'Z': [684]}]},\n {'P': [686, {'Z': [689]}]},\n {'P': [689, {'Z': [686]}]},\n {'P': [688, {'Z': [691, 693, 695]}]},\n {'P': [691, {'Z': [688, 695, 693]}]},\n {'P': [690, {'Z': [697, 701, 699]}]},\n {'P': [693, {'Z': [688, 691, 695]}]},\n {'P': [692, {'Z': [705, 707, 709]}]},\n {'P': [695, {'Z': [688, 693, 691]}]},\n {'P': [694]},\n {'P': [697, {'Z': [690, 699, 701]}]},\n {'P': [696, {'Z': [703]}]},\n {'P': [699, {'Z': [690, 701, 697]}]},\n {'P': [698]},\n {'P': [701, {'Z': [690, 697, 699]}]},\n {'P': [700]},\n {'P': [703, {'Z': [696]}]},\n {'P': [702]},\n {'P': [705, {'Z': [692, 709, 707]}]},\n {'P': [704, {'Z': [711, 713, 715]}]},\n {'P': [707, {'Z': [692, 705, 709]}]},\n {'P': [706]},\n {'P': [709, {'Z': [692, 707, 705]}]},\n {'P': [708]},\n {'P': [711, {'Z': [704, 715, 713]}]},\n {'P': [710, {'Z': [717, 721, 719]}]},\n {'P': [713, {'Z': [704, 711, 715]}]},\n {'P': [712]},\n {'P': [715, {'Z': [704, 713, 711]}]},\n {'P': [714]},\n {'P': [717, {'Z': [710, 719, 721]}]},\n {'P': [716, {'Z': [723, 725, 727]}]},\n {'P': [719, {'Z': [710, 721, 717]}]},\n {'P': [718]},\n {'P': [721, {'Z': [710, 717, 719]}]},\n {'P': [720]},\n {'P': [723, {'Z': [716, 727, 725]}]},\n {'P': [722, {'Z': [729, 731, 733]}]},\n {'P': [725, {'Z': [716, 723, 727]}]},\n {'P': [724]},\n {'P': [727, {'Z': [716, 725, 723]}]},\n {'P': [726]},\n {'P': [729, {'Z': [722, 733, 731]}]},\n {'P': [728, {'Z': [735, 737, 739]}]},\n {'P': [731, {'Z': [722, 729, 733]}]},\n {'P': [730]},\n {'P': [733, {'Z': [722, 731, 729]}]},\n {'P': [732]},\n {'P': [735, {'Z': [728, 739, 737]}]},\n {'P': [734, {'Z': [741, 745, 743]}]},\n {'P': [737, {'Z': [728, 735, 739]}]},\n {'P': [736]},\n {'P': [739, {'Z': [728, 737, 735]}]},\n {'P': [738]},\n {'P': [741, {'Z': [734, 743, 745]}]},\n {'P': [740, {'Z': [747, 751, 749]}]},\n {'P': [743, {'Z': [734, 745, 741]}]},\n {'P': [742]},\n {'P': [745, {'Z': [734, 741, 743]}]},\n {'P': [744]},\n {'P': [747, {'Z': [740, 749, 751]}]},\n {'P': [746]},\n {'P': [749, {'Z': [740, 751, 747]}]},\n {'P': [748]},\n {'P': [751, {'Z': [740, 747, 749]}]},\n {'P': [750]},\n {'P': [753, {'Z': [755]}]},\n {'P': [752, {'Z': [757]}]},\n {'P': [755, {'Z': [753]}]},\n {'P': [754]},\n {'P': [757, {'Z': [752]}]},\n {'P': [756, {'Z': [759]}]},\n {'P': [759, {'Z': [756]}]},\n {'P': [758, {'Z': [761]}]},\n {'P': [761, {'Z': [758]}]},\n {'P': [760, {'Z': [763]}]},\n {'P': [763, {'Z': [760]}]},\n {'P': [762, {'Z': [765]}]},\n {'P': [765, {'Z': [762]}]},\n {'P': [764, {'Z': [767]}]},\n {'P': [767, {'Z': [764]}]},\n {'P': [766, {'Z': [769]}]},\n {'P': [769, {'Z': [766]}]},\n {'P': [768, {'Z': [771, 775, 773]}]},\n {'P': [771, {'Z': [768, 773, 775]}]},\n {'P': [770, {'Z': [777, 779, 781]}]},\n {'P': [773, {'Z': [768, 775, 771]}]},\n {'P': [772, {'Z': [785, 789, 787]}]},\n {'P': [775, {'Z': [768, 771, 773]}]},\n {'P': [774]},\n {'P': [777, {'Z': [770, 781, 779]}]},\n {'P': [776, {'Z': [783]}]},\n {'P': [779, {'Z': [770, 777, 781]}]},\n {'P': [778]},\n {'P': [781, {'Z': [770, 779, 777]}]},\n {'P': [780]},\n {'P': [783, {'Z': [776]}]},\n {'P': [782]},\n {'P': [785, {'Z': [772, 787, 789]}]},\n {'P': [784, {'Z': [791, 793, 795]}]},\n {'P': [787, {'Z': [772, 789, 785]}]},\n {'P': [786]},\n {'P': [789, {'Z': [772, 785, 787]}]},\n {'P': [788]},\n {'P': [791, {'Z': [784, 795, 793]}]},\n {'P': [790, {'Z': [797, 801, 799]}]},\n {'P': [793, {'Z': [784, 791, 795]}]},\n {'P': [792]},\n {'P': [795, {'Z': [784, 793, 791]}]},\n {'P': [794]},\n {'P': [797, {'Z': [790, 799, 801]}]},\n {'P': [796, {'Z': [803, 805, 807]}]},\n {'P': [799, {'Z': [790, 801, 797]}]},\n {'P': [798]},\n {'P': [801, {'Z': [790, 797, 799]}]},\n {'P': [800]},\n {'P': [803, {'Z': [796, 807, 805]}]},\n {'P': [802, {'Z': [809, 811, 813]}]},\n {'P': [805, {'Z': [796, 803, 807]}]},\n {'P': [804]},\n {'P': [807, {'Z': [796, 805, 803]}]},\n {'P': [806]},\n {'P': [809, {'Z': [802, 813, 811]}]},\n {'P': [808, {'Z': [815, 817, 819]}]},\n {'P': [811, {'Z': [802, 809, 813]}]},\n {'P': [810]},\n {'P': [813, {'Z': [802, 811, 809]}]},\n {'P': [812]},\n {'P': [815, {'Z': [808, 819, 817]}]},\n {'P': [814, {'Z': [821, 825, 823]}]},\n {'P': [817, {'Z': [808, 815, 819]}]},\n {'P': [816]},\n {'P': [819, {'Z': [808, 817, 815]}]},\n {'P': [818]},\n {'P': [821, {'Z': [814, 823, 825]}]},\n {'P': [820, {'Z': [827, 829, 831]}]},\n {'P': [823, {'Z': [814, 825, 821]}]},\n {'P': [822]},\n {'P': [825, {'Z': [814, 821, 823]}]},\n {'P': [824]},\n {'P': [827, {'Z': [820, 831, 829]}]},\n {'P': [826]},\n {'P': [829, {'Z': [820, 827, 831]}]},\n {'P': [828]},\n {'P': [831, {'Z': [820, 829, 827]}]},\n {'P': [830]},\n {'P': [833, {'Z': [835]}]},\n {'P': [832, {'Z': [837]}]},\n {'P': [835, {'Z': [833]}]},\n {'P': [834]},\n {'P': [837, {'Z': [832]}]},\n {'P': [836, {'Z': [839, 841, 843]}]},\n {'P': [839, {'Z': [836, 843, 841]}]},\n {'P': [838, {'Z': [845, 847, 849]}]},\n {'P': [841, {'Z': [836, 839, 843]}]},\n {'P': [840, {'Z': [851]}]},\n {'P': [843, {'Z': [836, 841, 839]}]},\n {'P': [842]},\n {'P': [845, {'Z': [838, 849, 847]}]},\n {'P': [844]},\n {'P': [847, {'Z': [838, 845, 849]}]},\n {'P': [846]},\n {'P': [849, {'Z': [838, 847, 845]}]},\n {'P': [848]},\n {'P': [851, {'Z': [840]}]},\n {'P': [850, {'Z': [853, 855]}]},\n {'P': [853, {'Z': [850, 855]}]},\n {'P': [852, {'Z': [857, 859]}]},\n {'P': [855, {'Z': [850, 853]}]},\n {'P': [854, {'Z': [926, 931]}]},\n {'P': [857, {'Z': [852, 859]}]},\n {'P': [856]},\n {'P': [859, {'Z': [852, 857]}]},\n {'P': [858, {'Z': [861, 863]}]},\n {'P': [861, {'Z': [858, 863]}]},\n {'P': [860, {'Z': [865, 867]}]},\n {'P': [863, {'Z': [858, 861]}]},\n {'P': [862]},\n {'P': [865, {'Z': [860, 867]}]},\n {'P': [864, {'Z': [869]}]},\n {'P': [867, {'Z': [860, 865]}]},\n {'P': [866, {'Z': [927, 929]}]},\n {'P': [869, {'Z': [864]}]},\n {'P': [868, {'Z': [871, 875, 873]}]},\n {'P': [871, {'Z': [868, 873, 875]}]},\n {'P': [870, {'Z': [877, 879]}]},\n {'P': [873, {'Z': [868, 875, 871]}]},\n {'P': [872]},\n {'P': [875, {'Z': [868, 871, 873]}]},\n {'P': [874]},\n {'P': [877, {'Z': [870, 879]}]},\n {'P': [876, {'Z': [881, 883]}]},\n {'P': [879, {'Z': [870, 877]}]},\n {'P': [878, {'Z': [892, 897]}]},\n {'P': [881, {'Z': [876, 883]}]},\n {'P': [880, {'Z': [885, 887]}]},\n {'P': [883, {'Z': [876, 881]}]},\n {'P': [882]},\n {'P': [885, {'Z': [880, 887]}]},\n {'P': [884, {'Z': [889, 891]}]},\n {'P': [887, {'Z': [880, 885]}]},\n {'P': [886]},\n {'P': [889, {'Z': [884, 891]}]},\n {'P': [888, {'Z': [893, 895]}]},\n {'P': [891, {'Z': [884, 889]}]},\n {'P': [890]},\n {'P': [893, {'Z': [888, 895]}]},\n {'P': [892, {'Z': [878, 897]}]},\n {'P': [895, {'Z': [888, 893]}]},\n {'P': [894]},\n {'P': [897, {'Z': [878, 892]}]},\n {'P': [896, {'Z': [899, 901]}]},\n {'P': [899, {'Z': [896, 901]}]},\n {'P': [898, {'Z': [903]}]},\n {'P': [901, {'Z': [896, 899]}]},\n {'P': [900, {'Z': [913, 915]}]},\n {'P': [903, {'Z': [898]}]},\n {'P': [902, {'Z': [905]}]},\n {'P': [905, {'Z': [902]}]},\n {'P': [904, {'Z': [907, 909, 911]}]},\n {'P': [907, {'Z': [904, 911, 909]}]},\n {'P': [906]},\n {'P': [909, {'Z': [904, 907, 911]}]},\n {'P': [908]},\n {'P': [911, {'Z': [904, 909, 907]}]},\n {'P': [910]},\n {'P': [913, {'Z': [900, 915]}]},\n {'P': [912]},\n {'P': [915, {'Z': [900, 913]}]},\n {'P': [914, {'Z': [917, 919]}]},\n {'P': [917, {'Z': [914, 919]}]},\n {'P': [916, {'Z': [921, 925, 923]}]},\n {'P': [919, {'Z': [914, 917]}]},\n {'P': [918]},\n {'P': [921, {'Z': [916, 923, 925]}]},\n {'P': [920]},\n {'P': [923, {'Z': [916, 925, 921]}]},\n {'P': [922]},\n {'P': [925, {'Z': [916, 921, 923]}]},\n {'P': [924]},\n {'P': [927, {'Z': [866, 929]}]},\n {'P': [926, {'Z': [854, 931]}]},\n {'P': [929, {'Z': [866, 927]}]},\n {'P': [928]},\n {'P': [931, {'Z': [854, 926]}]},\n {'P': [930]},\n {'P': [933, {'Z': [935]}]},\n {'P': [932, {'Z': [937]}]},\n {'P': [935, {'Z': [933]}]},\n {'P': [934]},\n {'P': [937, {'Z': [932]}]},\n {'P': [936, {'Z': [939, 943, 941]}]},\n {'P': [939, {'Z': [936, 941, 943]}]},\n {'P': [938, {'Z': [945, 947, 949]}]},\n {'P': [941, {'Z': [936, 943, 939]}]},\n {'P': [940, {'Z': [951]}]},\n {'P': [943, {'Z': [936, 939, 941]}]},\n {'P': [942]},\n {'P': [945, {'Z': [938, 949, 947]}]},\n {'P': [944]},\n {'P': [947, {'Z': [938, 945, 949]}]},\n {'P': [946]},\n {'P': [949, {'Z': [938, 947, 945]}]},\n {'P': [948]},\n {'P': [951, {'Z': [940]}]},\n {'P': [950, {'Z': [953, 955]}]},\n {'P': [953, {'Z': [950, 955]}]},\n {'P': [952, {'Z': [957, 959]}]},\n {'P': [955, {'Z': [950, 953]}]},\n {'P': [954, {'Z': [1026, 1031]}]},\n {'P': [957, {'Z': [952, 959]}]},\n {'P': [956]},\n {'P': [959, {'Z': [952, 957]}]},\n {'P': [958, {'Z': [961, 963]}]},\n {'P': [961, {'Z': [958, 963]}]},\n {'P': [960, {'Z': [965, 967]}]},\n {'P': [963, {'Z': [958, 961]}]},\n {'P': [962]},\n {'P': [965, {'Z': [960, 967]}]},\n {'P': [964, {'Z': [969]}]},\n {'P': [967, {'Z': [960, 965]}]},\n {'P': [966, {'Z': [1027, 1029]}]},\n {'P': [969, {'Z': [964]}]},\n {'P': [968, {'Z': [971, 975, 973]}]},\n {'P': [971, {'Z': [968, 973, 975]}]},\n {'P': [970, {'Z': [977, 979]}]},\n {'P': [973, {'Z': [968, 975, 971]}]},\n {'P': [972]},\n {'P': [975, {'Z': [968, 971, 973]}]},\n {'P': [974]},\n {'P': [977, {'Z': [970, 979]}]},\n {'P': [976, {'Z': [981, 983]}]},\n {'P': [979, {'Z': [970, 977]}]},\n {'P': [978, {'Z': [992, 997]}]},\n {'P': [981, {'Z': [976, 983]}]},\n {'P': [980, {'Z': [985, 987]}]},\n {'P': [983, {'Z': [976, 981]}]},\n {'P': [982]},\n {'P': [985, {'Z': [980, 987]}]},\n {'P': [984, {'Z': [989, 991]}]},\n {'P': [987, {'Z': [980, 985]}]},\n {'P': [986]},\n {'P': [989, {'Z': [984, 991]}]},\n {'P': [988, {'Z': [993, 995]}]},\n {'P': [991, {'Z': [984, 989]}]},\n {'P': [990]},\n {'P': [993, {'Z': [988, 995]}]},\n {'P': [992, {'Z': [978, 997]}]},\n {'P': [995, {'Z': [988, 993]}]},\n {'P': [994]},\n {'P': [997, {'Z': [978, 992]}]},\n {'P': [996, {'Z': [999, 1001]}]},\n {'P': [999, {'Z': [996, 1001]}]},\n {'P': [998, {'Z': [1003]}]},\n ...]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_trees"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:13.982082Z",
     "end_time": "2024-03-12T19:37:14.052416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "2356"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(permutation_trees)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T14:52:30.021032Z",
     "end_time": "2024-03-13T14:52:30.044538Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def depth(d):\n",
    "    if isinstance(d, list):\n",
    "        return max(map(depth, d))\n",
    "    if isinstance(d, dict):\n",
    "        return 1 + (max(map(depth, d.values())) if d else 0)\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:18:26.646221Z",
     "end_time": "2024-03-13T16:18:26.655304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# get number of layers\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m num_layers \u001B[38;5;241m=\u001B[39m depth(\u001B[43mpermutation_trees\u001B[49m)\n\u001B[0;32m      3\u001B[0m num_layers\n",
      "\u001B[1;31mNameError\u001B[0m: name 'permutation_trees' is not defined"
     ]
    }
   ],
   "source": [
    "# get number of layers\n",
    "num_layers = depth(permutation_trees)\n",
    "num_layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:15.675936Z",
     "end_time": "2024-03-12T19:37:15.684942Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_at_depth(d: object, depth: int = 1) -> list:\n",
    "    if depth == 1:\n",
    "        # return the values\n",
    "        return list(d.values())\n",
    "    else:\n",
    "        return [\n",
    "            *get_at_depth(child, depth-1)\n",
    "            for child in d.values()\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get actions to take at level max\n",
    "actions = [\n",
    "\n",
    "    for tree in permutation_trees\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_matrix_layer_at_depth(tree, depth, k):\n",
    "    if isinstance(tree, int):\n",
    "        return tree\n",
    "    elif isinstance(tree, dict):\n",
    "        key = next(iter(tree.keys()))\n",
    "        l = get_matrix_layer_at_depth(tree[key], depth-1, k=k)\n",
    "        if depth == 1:\n",
    "\n",
    "    else:\n",
    "        return [\n",
    "            get_matrix_layer_at_depth(child, depth, k=k)\n",
    "            for child in tree\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_matrix(tree, depth, prefix: list = []) -> list:\n",
    "    if isinstance(tree, list):\n",
    "        return torch.cat([\n",
    "            get_matrix(child, depth, prefix + [idx])\n",
    "            for idx, child in enumerate(tree)\n",
    "        ], dim=-1)\n",
    "\n",
    "    elif isinstance(tree, dict):\n",
    "        key = next(iter(tree.keys()))\n",
    "        return get_matrix(tree[key], depth-1, prefix)\n",
    "\n",
    "    elif isinstance(tree, int):\n",
    "        return torch.tensor(prefix + [tree] + [-1]*depth)\n",
    "\n",
    "    else:\n",
    "        return [-1]\n",
    "\n",
    "temp = get_matrix(permutation_trees, depth=num_layers)\n",
    "temp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:17.869282Z",
     "end_time": "2024-03-12T19:37:17.903796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 18\u001B[0m temp \u001B[38;5;241m=\u001B[39m get_matrix(\u001B[43mpermutation_trees\u001B[49m, depth\u001B[38;5;241m=\u001B[39mnum_layers)\n\u001B[0;32m     19\u001B[0m temp[:\u001B[38;5;241m10\u001B[39m, :]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'permutation_trees' is not defined"
     ]
    }
   ],
   "source": [
    "def get_matrix(tree, depth, prefix: list = []) -> list:\n",
    "    if isinstance(tree, list):\n",
    "        return torch.cat([\n",
    "            get_matrix(child, depth, prefix + [idx])\n",
    "            for idx, child in enumerate(tree)\n",
    "        ], dim=0)\n",
    "\n",
    "    elif isinstance(tree, dict):\n",
    "        key = next(iter(tree.keys()))\n",
    "        return get_matrix(tree[key], depth-1, prefix)\n",
    "\n",
    "    elif isinstance(tree, int):\n",
    "        return torch.tensor(prefix + [tree] + [-1]*depth).reshape(1, -1)\n",
    "\n",
    "    else:\n",
    "        return [-1]\n",
    "\n",
    "temp = get_matrix(permutation_trees, depth=num_layers)\n",
    "temp[:10, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:37:20.610643Z",
     "end_time": "2024-03-12T19:37:20.681644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "type_dict = {\n",
    "    \"P\": 1,\n",
    "    \"Z\": 2\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:18:29.758389Z",
     "end_time": "2024-03-13T16:18:29.772476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 20\u001B[0m idx_matrix, type_matrix \u001B[38;5;241m=\u001B[39m get_matrix(\u001B[43mpermutation_trees\u001B[49m, depth\u001B[38;5;241m=\u001B[39mnum_layers)\n\u001B[0;32m     21\u001B[0m display(idx_matrix[:\u001B[38;5;241m10\u001B[39m])\n\u001B[0;32m     22\u001B[0m display(type_matrix[:\u001B[38;5;241m10\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'permutation_trees' is not defined"
     ]
    }
   ],
   "source": [
    "def get_matrix(tree, depth, idx_prefix: list = [], type_prefix: list = []) -> list:\n",
    "    if isinstance(tree, list):\n",
    "        idx_matrix, type_matrix = zip(*[\n",
    "            get_matrix(child, depth, idx_prefix + [idx], type_prefix)\n",
    "            for idx, child in enumerate(tree)\n",
    "        ])\n",
    "        return torch.cat(idx_matrix, dim=0), torch.cat(type_matrix, dim=0)\n",
    "\n",
    "    elif isinstance(tree, dict):\n",
    "        key = next(iter(tree.keys()))\n",
    "        return get_matrix(tree[key], depth - 1, idx_prefix, type_prefix=type_prefix + [type_dict[key]])\n",
    "\n",
    "    elif isinstance(tree, int):\n",
    "\n",
    "        return torch.tensor(idx_prefix + [tree] + [-1] * depth).reshape(1, -1), torch.tensor(type_prefix + [0]*depth).reshape(1, -1)\n",
    "\n",
    "    else:\n",
    "        return [-1]\n",
    "\n",
    "idx_matrix, type_matrix = get_matrix(permutation_trees, depth=num_layers)\n",
    "display(idx_matrix[:10])\n",
    "display(type_matrix[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:51:07.650174Z",
     "end_time": "2024-03-13T12:51:07.736099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch_geometric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:29.256285Z",
     "end_time": "2024-03-13T16:33:29.269285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3, 4, 5])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figuring out how global sum aggregation works\n",
    "torch_geometric.nn.pool.global_add_pool(torch.tensor([1,2,3,4,5]), torch.tensor([1,2,3,4,5]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:18:32.047071Z",
     "end_time": "2024-03-13T16:18:32.062072Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "alright put each colum of matrix to range 0 to ... to use addpool. for lowest part add more elements to thing like chienn. seperate matrix into vectors and do recursively to add up to top. different types after each other with mask then add up or set elements directly.\n",
    "\n",
    "the minus ones should be handled by pushing them to the rightmost and making that type defaulttype(=tunnel through)\n",
    "\n",
    "either apply all of this in batching or add to generation part like the permutation tree and then in batching collate accordingly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0],\n        [1, 0],\n        [1, 1],\n        [2, 0],\n        [2, 1],\n        [3, 0],\n        [3, 1],\n        [4, 0],\n        [4, 1],\n        [5, 0]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([1, 1, 3,  ..., 1, 3, 1])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_structure, second_layer_ = torch.unique(idx_matrix[:, :2], dim=0, return_counts=True)\n",
    "display(idx_structure[:10])\n",
    "display(second_layer_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:51:14.055254Z",
     "end_time": "2024-03-13T12:51:14.083758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([   0,    1,    2,  ..., 4122, 4122, 4123])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "second_layer = torch.repeat_interleave(second_layer_)\n",
    "display(second_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:51:16.054238Z",
     "end_time": "2024-03-13T12:51:16.142033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([   0,    1,    2,  ..., 4122, 4122, 4123])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:56:07.488808Z",
     "end_time": "2024-03-13T12:56:07.515383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[2, 0, 1],\n         [2, 0, 1],\n         [2, 0, 1]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[0]]),\n tensor([[1, 0],\n         [1, 0]]),\n tensor([[0]]),\n tensor([[0]]),\n ...]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "second_roller = [\n",
    "    torch.roll(torch.arange(elem), shifts=1).repeat(elem, 1)\n",
    "    for elem in second_layer_\n",
    "]\n",
    "display(second_roller)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:59:47.519883Z",
     "end_time": "2024-03-13T12:59:47.609398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(torch.tensor([1,2,3,5]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:55:35.061184Z",
     "end_time": "2024-03-13T12:55:35.076183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 2,  ..., 1, 2, 1])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, first_layer = torch.unique(idx_structure[:, :1], dim=0, return_counts=True)\n",
    "display(first_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T21:50:15.827409Z",
     "end_time": "2024-03-12T21:50:15.859917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([   0,    1,    1,  ..., 2354, 2354, 2355])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_layer_ = torch.tensor(list(chain(*[\n",
    "    [idx] * elem\n",
    "    for idx, elem in enumerate(first_layer)\n",
    "])))\n",
    "display(first_layer_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T21:50:16.415050Z",
     "end_time": "2024-03-12T21:50:16.475177Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "alright... transformation is clear - each time it gets smaller (the -1 needs to be replaced with the value to the left consistently)\n",
    "\n",
    "and... the thing with the type tensor... let's do it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 1,  ..., 1, 1, 1])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = 0\n",
    "types = []\n",
    "for i in first_layer:\n",
    "    types.append(type_matrix[counter, 0])\n",
    "    counter += i\n",
    "types = torch.tensor(types)\n",
    "display(types)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:17:21.694643Z",
     "end_time": "2024-03-13T12:17:21.719644Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get rid of -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   0,    0,    1,    1],\n        [   1,    0,    0,    0],\n        [   1,    1,    0,    3],\n        ...,\n        [2354,    1,    1, 2351],\n        [2354,    1,    2, 2353],\n        [2355,    0, 2354, 2354]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = (idx_matrix[:, -1] == -1)\n",
    "idx_matrix[temp, -1] = idx_matrix[temp, -2]\n",
    "display(idx_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:22:02.225206Z",
     "end_time": "2024-03-13T12:22:02.248206Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# add shifted column according to k"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_layer[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# put through embeddings - evtl nicht modulelist und dann cat sondern linear(hidden, k*hidden) und dann reshape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([   1,    0,    3,  ..., 2351, 2353, 2354])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_layer = idx_matrix[:, -1]\n",
    "display(last_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:22:29.705315Z",
     "end_time": "2024-03-13T12:22:29.717319Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "['H',\n 'T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_priority__',\n '__array_wrap__',\n '__bool__',\n '__class__',\n '__complex__',\n '__contains__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__div__',\n '__dlpack__',\n '__dlpack_device__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__idiv__',\n '__ifloordiv__',\n '__ilshift__',\n '__imod__',\n '__imul__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__long__',\n '__lshift__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__nonzero__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdiv__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__torch_dispatch__',\n '__torch_function__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_addmm_activation',\n '_autocast_to_full_precision',\n '_autocast_to_reduced_precision',\n '_backward_hooks',\n '_base',\n '_cdata',\n '_coalesced_',\n '_conj',\n '_conj_physical',\n '_dimI',\n '_dimV',\n '_fix_weakref',\n '_grad',\n '_grad_fn',\n '_has_symbolic_sizes_strides',\n '_indices',\n '_is_all_true',\n '_is_any_true',\n '_is_view',\n '_is_zerotensor',\n '_make_subclass',\n '_make_wrapper_subclass',\n '_neg_view',\n '_nested_tensor_size',\n '_nested_tensor_storage_offsets',\n '_nested_tensor_strides',\n '_nnz',\n '_post_accumulate_grad_hooks',\n '_python_dispatch',\n '_reduce_ex_internal',\n '_sparse_mask_projection',\n '_to_dense',\n '_to_sparse',\n '_to_sparse_bsc',\n '_to_sparse_bsr',\n '_to_sparse_csc',\n '_to_sparse_csr',\n '_typed_storage',\n '_update_names',\n '_values',\n '_version',\n '_view_func',\n '_view_func_unsafe',\n 'abs',\n 'abs_',\n 'absolute',\n 'absolute_',\n 'acos',\n 'acos_',\n 'acosh',\n 'acosh_',\n 'add',\n 'add_',\n 'addbmm',\n 'addbmm_',\n 'addcdiv',\n 'addcdiv_',\n 'addcmul',\n 'addcmul_',\n 'addmm',\n 'addmm_',\n 'addmv',\n 'addmv_',\n 'addr',\n 'addr_',\n 'adjoint',\n 'align_as',\n 'align_to',\n 'all',\n 'allclose',\n 'amax',\n 'amin',\n 'aminmax',\n 'angle',\n 'any',\n 'apply_',\n 'arccos',\n 'arccos_',\n 'arccosh',\n 'arccosh_',\n 'arcsin',\n 'arcsin_',\n 'arcsinh',\n 'arcsinh_',\n 'arctan',\n 'arctan2',\n 'arctan2_',\n 'arctan_',\n 'arctanh',\n 'arctanh_',\n 'argmax',\n 'argmin',\n 'argsort',\n 'argwhere',\n 'as_strided',\n 'as_strided_',\n 'as_strided_scatter',\n 'as_subclass',\n 'asin',\n 'asin_',\n 'asinh',\n 'asinh_',\n 'atan',\n 'atan2',\n 'atan2_',\n 'atan_',\n 'atanh',\n 'atanh_',\n 'backward',\n 'baddbmm',\n 'baddbmm_',\n 'bernoulli',\n 'bernoulli_',\n 'bfloat16',\n 'bincount',\n 'bitwise_and',\n 'bitwise_and_',\n 'bitwise_left_shift',\n 'bitwise_left_shift_',\n 'bitwise_not',\n 'bitwise_not_',\n 'bitwise_or',\n 'bitwise_or_',\n 'bitwise_right_shift',\n 'bitwise_right_shift_',\n 'bitwise_xor',\n 'bitwise_xor_',\n 'bmm',\n 'bool',\n 'broadcast_to',\n 'byte',\n 'cauchy_',\n 'ccol_indices',\n 'cdouble',\n 'ceil',\n 'ceil_',\n 'cfloat',\n 'chalf',\n 'char',\n 'cholesky',\n 'cholesky_inverse',\n 'cholesky_solve',\n 'chunk',\n 'clamp',\n 'clamp_',\n 'clamp_max',\n 'clamp_max_',\n 'clamp_min',\n 'clamp_min_',\n 'clip',\n 'clip_',\n 'clone',\n 'coalesce',\n 'col_indices',\n 'conj',\n 'conj_physical',\n 'conj_physical_',\n 'contiguous',\n 'copy_',\n 'copysign',\n 'copysign_',\n 'corrcoef',\n 'cos',\n 'cos_',\n 'cosh',\n 'cosh_',\n 'count_nonzero',\n 'cov',\n 'cpu',\n 'cross',\n 'crow_indices',\n 'cuda',\n 'cummax',\n 'cummin',\n 'cumprod',\n 'cumprod_',\n 'cumsum',\n 'cumsum_',\n 'data',\n 'data_ptr',\n 'deg2rad',\n 'deg2rad_',\n 'dense_dim',\n 'dequantize',\n 'det',\n 'detach',\n 'detach_',\n 'device',\n 'diag',\n 'diag_embed',\n 'diagflat',\n 'diagonal',\n 'diagonal_scatter',\n 'diff',\n 'digamma',\n 'digamma_',\n 'dim',\n 'dim_order',\n 'dist',\n 'div',\n 'div_',\n 'divide',\n 'divide_',\n 'dot',\n 'double',\n 'dsplit',\n 'dtype',\n 'eig',\n 'element_size',\n 'eq',\n 'eq_',\n 'equal',\n 'erf',\n 'erf_',\n 'erfc',\n 'erfc_',\n 'erfinv',\n 'erfinv_',\n 'exp',\n 'exp2',\n 'exp2_',\n 'exp_',\n 'expand',\n 'expand_as',\n 'expm1',\n 'expm1_',\n 'exponential_',\n 'fill_',\n 'fill_diagonal_',\n 'fix',\n 'fix_',\n 'flatten',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float',\n 'float_power',\n 'float_power_',\n 'floor',\n 'floor_',\n 'floor_divide',\n 'floor_divide_',\n 'fmax',\n 'fmin',\n 'fmod',\n 'fmod_',\n 'frac',\n 'frac_',\n 'frexp',\n 'gather',\n 'gcd',\n 'gcd_',\n 'ge',\n 'ge_',\n 'geometric_',\n 'geqrf',\n 'ger',\n 'get_device',\n 'grad',\n 'grad_fn',\n 'greater',\n 'greater_',\n 'greater_equal',\n 'greater_equal_',\n 'gt',\n 'gt_',\n 'half',\n 'hardshrink',\n 'has_names',\n 'heaviside',\n 'heaviside_',\n 'histc',\n 'histogram',\n 'hsplit',\n 'hypot',\n 'hypot_',\n 'i0',\n 'i0_',\n 'igamma',\n 'igamma_',\n 'igammac',\n 'igammac_',\n 'imag',\n 'index_add',\n 'index_add_',\n 'index_copy',\n 'index_copy_',\n 'index_fill',\n 'index_fill_',\n 'index_put',\n 'index_put_',\n 'index_reduce',\n 'index_reduce_',\n 'index_select',\n 'indices',\n 'inner',\n 'int',\n 'int_repr',\n 'inverse',\n 'ipu',\n 'is_coalesced',\n 'is_complex',\n 'is_conj',\n 'is_contiguous',\n 'is_cpu',\n 'is_cuda',\n 'is_distributed',\n 'is_floating_point',\n 'is_inference',\n 'is_ipu',\n 'is_leaf',\n 'is_meta',\n 'is_mkldnn',\n 'is_mps',\n 'is_mtia',\n 'is_neg',\n 'is_nested',\n 'is_nonzero',\n 'is_ort',\n 'is_pinned',\n 'is_quantized',\n 'is_same_size',\n 'is_set_to',\n 'is_shared',\n 'is_signed',\n 'is_sparse',\n 'is_sparse_csr',\n 'is_vulkan',\n 'is_xla',\n 'is_xpu',\n 'isclose',\n 'isfinite',\n 'isinf',\n 'isnan',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'istft',\n 'item',\n 'itemsize',\n 'kron',\n 'kthvalue',\n 'layout',\n 'lcm',\n 'lcm_',\n 'ldexp',\n 'ldexp_',\n 'le',\n 'le_',\n 'lerp',\n 'lerp_',\n 'less',\n 'less_',\n 'less_equal',\n 'less_equal_',\n 'lgamma',\n 'lgamma_',\n 'log',\n 'log10',\n 'log10_',\n 'log1p',\n 'log1p_',\n 'log2',\n 'log2_',\n 'log_',\n 'log_normal_',\n 'log_softmax',\n 'logaddexp',\n 'logaddexp2',\n 'logcumsumexp',\n 'logdet',\n 'logical_and',\n 'logical_and_',\n 'logical_not',\n 'logical_not_',\n 'logical_or',\n 'logical_or_',\n 'logical_xor',\n 'logical_xor_',\n 'logit',\n 'logit_',\n 'logsumexp',\n 'long',\n 'lstsq',\n 'lt',\n 'lt_',\n 'lu',\n 'lu_solve',\n 'mH',\n 'mT',\n 'map2_',\n 'map_',\n 'masked_fill',\n 'masked_fill_',\n 'masked_scatter',\n 'masked_scatter_',\n 'masked_select',\n 'matmul',\n 'matrix_exp',\n 'matrix_power',\n 'max',\n 'maximum',\n 'mean',\n 'median',\n 'min',\n 'minimum',\n 'mm',\n 'mode',\n 'moveaxis',\n 'movedim',\n 'msort',\n 'mul',\n 'mul_',\n 'multinomial',\n 'multiply',\n 'multiply_',\n 'mv',\n 'mvlgamma',\n 'mvlgamma_',\n 'name',\n 'names',\n 'nan_to_num',\n 'nan_to_num_',\n 'nanmean',\n 'nanmedian',\n 'nanquantile',\n 'nansum',\n 'narrow',\n 'narrow_copy',\n 'nbytes',\n 'ndim',\n 'ndimension',\n 'ne',\n 'ne_',\n 'neg',\n 'neg_',\n 'negative',\n 'negative_',\n 'nelement',\n 'new',\n 'new_empty',\n 'new_empty_strided',\n 'new_full',\n 'new_ones',\n 'new_tensor',\n 'new_zeros',\n 'nextafter',\n 'nextafter_',\n 'nonzero',\n 'nonzero_static',\n 'norm',\n 'normal_',\n 'not_equal',\n 'not_equal_',\n 'numel',\n 'numpy',\n 'orgqr',\n 'ormqr',\n 'outer',\n 'output_nr',\n 'permute',\n 'pin_memory',\n 'pinverse',\n 'polygamma',\n 'polygamma_',\n 'positive',\n 'pow',\n 'pow_',\n 'prelu',\n 'prod',\n 'put',\n 'put_',\n 'q_per_channel_axis',\n 'q_per_channel_scales',\n 'q_per_channel_zero_points',\n 'q_scale',\n 'q_zero_point',\n 'qr',\n 'qscheme',\n 'quantile',\n 'rad2deg',\n 'rad2deg_',\n 'random_',\n 'ravel',\n 'real',\n 'reciprocal',\n 'reciprocal_',\n 'record_stream',\n 'refine_names',\n 'register_hook',\n 'register_post_accumulate_grad_hook',\n 'reinforce',\n 'relu',\n 'relu_',\n 'remainder',\n 'remainder_',\n 'rename',\n 'rename_',\n 'renorm',\n 'renorm_',\n 'repeat',\n 'repeat_interleave',\n 'requires_grad',\n 'requires_grad_',\n 'reshape',\n 'reshape_as',\n 'resize',\n 'resize_',\n 'resize_as',\n 'resize_as_',\n 'resize_as_sparse_',\n 'resolve_conj',\n 'resolve_neg',\n 'retain_grad',\n 'retains_grad',\n 'roll',\n 'rot90',\n 'round',\n 'round_',\n 'row_indices',\n 'rsqrt',\n 'rsqrt_',\n 'scatter',\n 'scatter_',\n 'scatter_add',\n 'scatter_add_',\n 'scatter_reduce',\n 'scatter_reduce_',\n 'select',\n 'select_scatter',\n 'set_',\n 'sgn',\n 'sgn_',\n 'shape',\n 'share_memory_',\n 'short',\n 'sigmoid',\n 'sigmoid_',\n 'sign',\n 'sign_',\n 'signbit',\n 'sin',\n 'sin_',\n 'sinc',\n 'sinc_',\n 'sinh',\n 'sinh_',\n 'size',\n 'slice_scatter',\n 'slogdet',\n 'smm',\n 'softmax',\n 'solve',\n 'sort',\n 'sparse_dim',\n 'sparse_mask',\n 'sparse_resize_',\n 'sparse_resize_and_clear_',\n 'split',\n 'split_with_sizes',\n 'sqrt',\n 'sqrt_',\n 'square',\n 'square_',\n 'squeeze',\n 'squeeze_',\n 'sspaddmm',\n 'std',\n 'stft',\n 'storage',\n 'storage_offset',\n 'storage_type',\n 'stride',\n 'sub',\n 'sub_',\n 'subtract',\n 'subtract_',\n 'sum',\n 'sum_to_size',\n 'svd',\n 'swapaxes',\n 'swapaxes_',\n 'swapdims',\n 'swapdims_',\n 'symeig',\n 't',\n 't_',\n 'take',\n 'take_along_dim',\n 'tan',\n 'tan_',\n 'tanh',\n 'tanh_',\n 'tensor_split',\n 'tile',\n 'to',\n 'to_dense',\n 'to_mkldnn',\n 'to_padded_tensor',\n 'to_sparse',\n 'to_sparse_bsc',\n 'to_sparse_bsr',\n 'to_sparse_coo',\n 'to_sparse_csc',\n 'to_sparse_csr',\n 'tolist',\n 'topk',\n 'trace',\n 'transpose',\n 'transpose_',\n 'triangular_solve',\n 'tril',\n 'tril_',\n 'triu',\n 'triu_',\n 'true_divide',\n 'true_divide_',\n 'trunc',\n 'trunc_',\n 'type',\n 'type_as',\n 'unbind',\n 'unflatten',\n 'unfold',\n 'uniform_',\n 'unique',\n 'unique_consecutive',\n 'unsafe_chunk',\n 'unsafe_split',\n 'unsafe_split_with_sizes',\n 'unsqueeze',\n 'unsqueeze_',\n 'untyped_storage',\n 'values',\n 'var',\n 'vdot',\n 'view',\n 'view_as',\n 'vsplit',\n 'where',\n 'xlogy',\n 'xlogy_',\n 'xpu',\n 'zero_']"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(last_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:24:44.151577Z",
     "end_time": "2024-03-13T12:24:44.185575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6416])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:32:32.780079Z",
     "end_time": "2024-03-13T12:32:32.793085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6416, 118])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x[last_layer].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:32:21.141561Z",
     "end_time": "2024-03-13T12:32:21.158560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6416, 3, 118])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp1 = torch.stack([\n",
    "    emb(batch.x[last_layer])\n",
    "    for idx, emb in enumerate(k_list)\n",
    "], dim=1)\n",
    "display(temp1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T12:35:46.431883Z",
     "end_time": "2024-03-13T12:35:46.457301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sum over the k layers\n",
    "# then elu\n",
    "# then linear layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[75], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Masterarbeit_PTGNN\\lib\\site-packages\\torch\\nn\\modules\\linear.py:98\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[1;34m(self, in_features, out_features, bias, device, dtype)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_features \u001B[38;5;241m=\u001B[39m in_features\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_features \u001B[38;5;241m=\u001B[39m out_features\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m Parameter(torch\u001B[38;5;241m.\u001B[39mempty((out_features, in_features), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfactory_kwargs))\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bias:\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;241m=\u001B[39m Parameter(torch\u001B[38;5;241m.\u001B[39mempty(out_features, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfactory_kwargs))\n",
      "\u001B[1;31mTypeError\u001B[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "torch.nn.Linear(3, (3,2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "<class 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "selection = temp[0]\n",
    "print(selection)\n",
    "print(type(selection))\n",
    "print(len(selection))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T16:14:12.752315Z",
     "end_time": "2024-03-12T16:14:12.755316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[-1]*0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T16:58:07.469425Z",
     "end_time": "2024-03-12T16:58:07.493941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# simplistic version:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "k=3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:20:39.244971Z",
     "end_time": "2024-03-13T16:20:39.254969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "z_layer = torch.nn.ModuleList([\n",
    "    torch.nn.Linear(118, 118)\n",
    "    for _ in range(k)\n",
    "])\n",
    "z_final_layer = torch.nn.Linear(118,118)\n",
    "z_elu = torch.nn.ELU()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:13:57.716980Z",
     "end_time": "2024-03-13T16:13:57.728981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "p_layer = torch.nn.Linear(118, 118)\n",
    "p_final_layer = torch.nn.Linear(118, 118)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:13:58.668159Z",
     "end_time": "2024-03-13T16:13:58.692159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def fetch_or_produce(subtree):\n",
    "    if isinstance(subtree, int):\n",
    "        return batch.x[subtree]\n",
    "    else:\n",
    "        return fulfill_module(subtree)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:13:59.823165Z",
     "end_time": "2024-03-13T16:13:59.834165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def fulfill_module(tree):\n",
    "    # get node type\n",
    "    node_type = next(iter(tree.keys()))\n",
    "\n",
    "    # iterate over indices/trees and replace by data\n",
    "    data_list = [\n",
    "        fetch_or_produce(subtree)\n",
    "        for subtree in tree[node_type]\n",
    "    ]\n",
    "\n",
    "    data_list = torch.stack(data_list)\n",
    "\n",
    "    # put through layer\n",
    "    if node_type == \"P\":\n",
    "        # run through layer for each input\n",
    "        after_p = p_layer(data_list)\n",
    "        # sum up\n",
    "        after_p = torch.sum(after_p, dim=0)\n",
    "        # put through final linear layer\n",
    "        after_p = p_final_layer(after_p)\n",
    "\n",
    "        return after_p\n",
    "\n",
    "    elif node_type == \"Z\":\n",
    "        # run through embedding layers\n",
    "        after_z = [\n",
    "            layer(data_list)\n",
    "            for layer in z_layer\n",
    "        ]\n",
    "        # shift\n",
    "        _idx = torch.arange(data_list.shape[0])\n",
    "        after_z = [\n",
    "            embedding[torch.roll(_idx, shifts=idx), :]\n",
    "            for idx, embedding in enumerate(after_z)\n",
    "        ]\n",
    "        after_z = torch.stack(after_z)\n",
    "        # sum\n",
    "        after_z = torch.sum(after_z, dim=0)\n",
    "        # apply ELU\n",
    "        after_z = z_elu(after_z)\n",
    "        # layer\n",
    "        after_z = z_final_layer(after_z)\n",
    "        # sum\n",
    "        after_z = torch.sum(after_z, dim=0)\n",
    "        return after_z\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:14:00.232346Z",
     "end_time": "2024-03-13T16:14:00.277345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4, 1, 2, 3])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4])[torch.roll(torch.arange(4), shifts=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:14:01.484790Z",
     "end_time": "2024-03-13T16:14:01.505797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\n\u001B[0;32m      2\u001B[0m     fulfill_module(ptree)\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ptree \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpermutation_trees\u001B[49m\n\u001B[0;32m      4\u001B[0m ])\n\u001B[0;32m      5\u001B[0m display(out)\n\u001B[0;32m      6\u001B[0m display(out\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'permutation_trees' is not defined"
     ]
    }
   ],
   "source": [
    "out = torch.stack([\n",
    "    fulfill_module(ptree)\n",
    "    for ptree in permutation_trees\n",
    "])\n",
    "display(out)\n",
    "display(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T19:12:01.949405Z",
     "end_time": "2024-03-12T19:12:02.440415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m new_node_values \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ptree \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpermutation_trees\u001B[49m:\n\u001B[0;32m      3\u001B[0m     new_node_values\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m      4\u001B[0m         fulfill_module(ptree)\n\u001B[0;32m      5\u001B[0m     )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'permutation_trees' is not defined"
     ]
    }
   ],
   "source": [
    "new_node_values = []\n",
    "for ptree in permutation_trees:\n",
    "    new_node_values.append(\n",
    "        fulfill_module(ptree)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T17:16:38.087130Z",
     "end_time": "2024-03-12T17:16:38.115131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:39.943845Z",
     "end_time": "2024-03-13T16:33:39.953846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1721 [00:08<28:02,  1.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 19\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# extract permutation trees from string\u001B[39;00m\n\u001B[0;32m     14\u001B[0m permutation_trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     15\u001B[0m     json\u001B[38;5;241m.\u001B[39mloads(p_string)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p_string \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mptree\n\u001B[0;32m     17\u001B[0m ]\n\u001B[1;32m---> 19\u001B[0m new_node_values \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     20\u001B[0m     fulfill_module(ptree)\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ptree \u001B[38;5;129;01min\u001B[39;00m permutation_trees\n\u001B[0;32m     22\u001B[0m ]\n",
      "Cell \u001B[1;32mIn[23], line 20\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# extract permutation trees from string\u001B[39;00m\n\u001B[0;32m     14\u001B[0m permutation_trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     15\u001B[0m     json\u001B[38;5;241m.\u001B[39mloads(p_string)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p_string \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mptree\n\u001B[0;32m     17\u001B[0m ]\n\u001B[0;32m     19\u001B[0m new_node_values \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m---> 20\u001B[0m     \u001B[43mfulfill_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mptree\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ptree \u001B[38;5;129;01min\u001B[39;00m permutation_trees\n\u001B[0;32m     22\u001B[0m ]\n",
      "Cell \u001B[1;32mIn[18], line 6\u001B[0m, in \u001B[0;36mfulfill_module\u001B[1;34m(tree)\u001B[0m\n\u001B[0;32m      3\u001B[0m node_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(tree\u001B[38;5;241m.\u001B[39mkeys()))\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# iterate over indices/trees and replace by data\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m data_list \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      7\u001B[0m     fetch_or_produce(subtree)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subtree \u001B[38;5;129;01min\u001B[39;00m tree[node_type]\n\u001B[0;32m      9\u001B[0m ]\n\u001B[0;32m     11\u001B[0m data_list \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(data_list)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# put through layer\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[18], line 7\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      3\u001B[0m node_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(tree\u001B[38;5;241m.\u001B[39mkeys()))\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# iterate over indices/trees and replace by data\u001B[39;00m\n\u001B[0;32m      6\u001B[0m data_list \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m----> 7\u001B[0m     \u001B[43mfetch_or_produce\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubtree\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subtree \u001B[38;5;129;01min\u001B[39;00m tree[node_type]\n\u001B[0;32m      9\u001B[0m ]\n\u001B[0;32m     11\u001B[0m data_list \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(data_list)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# put through layer\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[17], line 5\u001B[0m, in \u001B[0;36mfetch_or_produce\u001B[1;34m(subtree)\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mx[subtree]\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m----> 5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfulfill_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubtree\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[18], line 32\u001B[0m, in \u001B[0;36mfulfill_module\u001B[1;34m(tree)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# shift\u001B[39;00m\n\u001B[0;32m     31\u001B[0m _idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(data_list\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m---> 32\u001B[0m after_z \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     33\u001B[0m     embedding[torch\u001B[38;5;241m.\u001B[39mroll(_idx, shifts\u001B[38;5;241m=\u001B[39midx), :]\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(after_z)\n\u001B[0;32m     35\u001B[0m ]\n\u001B[0;32m     36\u001B[0m after_z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(after_z)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# sum\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[18], line 33\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# shift\u001B[39;00m\n\u001B[0;32m     31\u001B[0m _idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(data_list\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     32\u001B[0m after_z \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m---> 33\u001B[0m     \u001B[43membedding\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroll\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshifts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(after_z)\n\u001B[0;32m     35\u001B[0m ]\n\u001B[0;32m     36\u001B[0m after_z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(after_z)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# sum\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "z_elu = z_elu.to(device)\n",
    "z_layer = z_layer.to(device)\n",
    "z_final_layer = z_final_layer.to(device)\n",
    "\n",
    "p_layer = p_layer.to(device)\n",
    "p_final_layer = p_final_layer.to(device)\n",
    "\n",
    "for train_batch in tqdm(train_loader):\n",
    "    # to device\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # extract permutation trees from string\n",
    "    permutation_trees = [\n",
    "        json.loads(p_string)\n",
    "        for p_string in batch.ptree\n",
    "    ]\n",
    "\n",
    "    new_node_values = [\n",
    "        fulfill_module(ptree)\n",
    "        for ptree in permutation_trees\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Complicated approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from ptgnn.model.modules.ptree.complex_ptree_layer import ComplexPtreeLayer\n",
    "from ptgnn.transform.ptree_matrix import permutation_tree_to_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:42.013917Z",
     "end_time": "2024-03-13T16:33:42.026917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = ComplexPtreeLayer(3, 118)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:42.613086Z",
     "end_time": "2024-03-13T16:33:42.622084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# device = 'cuda'\n",
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:38:06.913638Z",
     "end_time": "2024-03-13T16:38:06.923639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:38:07.428499Z",
     "end_time": "2024-03-13T16:38:07.448497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1721/1721 [03:26<00:00,  8.34it/s]\n"
     ]
    }
   ],
   "source": [
    "temp = [\n",
    "    permutation_tree_to_matrix(train_batch.ptree, 3)\n",
    "    for train_batch in tqdm(train_loader)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:33:44.421732Z",
     "end_time": "2024-03-13T16:37:10.850616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 118/1721 [00:27<06:13,  4.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# to device\u001B[39;00m\n\u001B[0;32m      5\u001B[0m train_batch \u001B[38;5;241m=\u001B[39m train_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_batch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Masterarbeit_PTGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Masterarbeit_PTGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\DATEN\\Masterarbeit_PTGNN\\ptgnn\\model\\modules\\ptree\\complex_ptree_layer.py:61\u001B[0m, in \u001B[0;36mComplexPtreeLayer.forward\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     59\u001B[0m     r \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(cur_pos, cur_pos\u001B[38;5;241m+\u001B[39mi)\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(current_k):\n\u001B[1;32m---> 61\u001B[0m         order_matrix[:current_k, cur_pos\u001B[38;5;241m+\u001B[39mj] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mroll(r, shifts\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mj)\n\u001B[0;32m     62\u001B[0m     cur_pos \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m i\n\u001B[0;32m     64\u001B[0m \u001B[38;5;66;03m# add zero padding to data list\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for train_batch, t in zip(tqdm(train_loader), temp):\n",
    "    train_batch.idx_matrix, train_batch.type_matrix = t # permutation_tree_to_matrix(train_batch.ptree, 3)\n",
    "\n",
    "    # to device\n",
    "    train_batch = train_batch.to(device)\n",
    "\n",
    "    model(train_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:14:27.786227Z",
     "end_time": "2024-03-13T16:15:09.402891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "batch.idx_matrix, batch.type_matrix = permutation_tree_to_matrix(batch.ptree, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:17.163784Z",
     "end_time": "2024-03-13T15:59:17.257756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T15:59:19.271270Z",
     "end_time": "2024-03-13T15:59:19.470361Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T16:13:02.218699Z",
     "end_time": "2024-03-13T16:13:02.233700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
