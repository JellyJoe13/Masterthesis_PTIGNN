{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-28T21:55:17.238287Z",
     "end_time": "2024-03-28T21:55:27.047927Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "from ptgnn.runtime_config.config import import_as, export_as\n",
    "from ptgnn.runtime_config.config_helpers import run_config_adapter, load_and_merge_default_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "storage_path = \"C:/Users/johan/ray_results/\"\n",
    "# storage_path = \"D:/DATEN/Masterarbeit_PTGNN/notebooks/hyperoptimization/ray_temp\"\n",
    "exp_name = \"ba_1\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T22:00:50.214390Z",
     "end_time": "2024-03-28T22:00:50.228392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from C:/Users/johan/ray_results/ba_1...\n"
     ]
    }
   ],
   "source": [
    "experiment_path = os.path.join(storage_path, exp_name)\n",
    "print(f\"Loading results from {experiment_path}...\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T22:00:50.782968Z",
     "end_time": "2024-03-28T22:00:50.815475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def trainable_function(config):\n",
    "    run_config_adapter(\n",
    "        config,\n",
    "        default_config={},\n",
    "        report=True,\n",
    "        verbose=False,\n",
    "        device=None\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T22:00:52.286923Z",
     "end_time": "2024-03-28T22:00:52.303436Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't return results as experiment has not been run, yet. Call `Tuner.fit()` to run the experiment first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m restored_tuner \u001B[38;5;241m=\u001B[39m tune\u001B[38;5;241m.\u001B[39mTuner\u001B[38;5;241m.\u001B[39mrestore(\n\u001B[0;32m      2\u001B[0m     experiment_path,\n\u001B[0;32m      3\u001B[0m     trainable\u001B[38;5;241m=\u001B[39mtrainable_function\n\u001B[0;32m      4\u001B[0m )\n\u001B[1;32m----> 5\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mrestored_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Masterarbeit_PTGNN\\lib\\site-packages\\ray\\tune\\tuner.py:431\u001B[0m, in \u001B[0;36mTuner.get_results\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get results of a hyperparameter tuning run.\u001B[39;00m\n\u001B[0;32m    411\u001B[0m \n\u001B[0;32m    412\u001B[0m \u001B[38;5;124;03mThis method returns the same results as :meth:`fit() <ray.tune.tuner.Tuner.fit>`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    428\u001B[0m \n\u001B[0;32m    429\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    430\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_ray_client:\n\u001B[1;32m--> 431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_local_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    433\u001B[0m     (\n\u001B[0;32m    434\u001B[0m         progress_reporter,\n\u001B[0;32m    435\u001B[0m         string_queue,\n\u001B[0;32m    436\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_remote_tuner_for_jupyter_progress_reporting()\n",
      "File \u001B[1;32m~\\.conda\\envs\\Masterarbeit_PTGNN\\lib\\site-packages\\ray\\tune\\impl\\tuner_internal.py:519\u001B[0m, in \u001B[0;36mTunerInternal.get_results\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_results\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResultGrid:\n\u001B[0;32m    518\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experiment_analysis:\n\u001B[1;32m--> 519\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    520\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt return results as experiment has not been run, yet. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    521\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCall `Tuner.fit()` to run the experiment first.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    522\u001B[0m         )\n\u001B[0;32m    523\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ResultGrid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experiment_analysis)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Can't return results as experiment has not been run, yet. Call `Tuner.fit()` to run the experiment first."
     ]
    }
   ],
   "source": [
    "restored_tuner = tune.Tuner.restore(\n",
    "    experiment_path,\n",
    "    trainable=trainable_function\n",
    ")\n",
    "results = restored_tuner.get_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:52:26.280941Z",
     "end_time": "2024-03-28T06:52:26.694723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ResultGrid<[\n  Result(\n    metrics={'train_mae': 0.66, 'train_r2': 0.16, 'train_spearmanr': 0.59, 'train_mse': 0.73, 'train_rmse': 0.86, 'train_mean_loss': 0.6619604009980211, 'train_sum_loss': 207.1936055123806, 'val_mae': 1.52, 'val_r2': -2.81, 'val_spearmanr': 0.32, 'val_mse': 3.5, 'val_rmse': 1.87, 'val_mean_loss': 1.520460289126387, 'val_sum_loss': 475.90407049655914},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_9728a09d_1_hidden_dimension=64,dropout=0.5000,times=3,base_learning_rate=0.0000_2024-03-27_15-37-57',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.74, 'train_r2': -0.06, 'train_spearmanr': 0.49, 'train_mse': 0.92, 'train_rmse': 0.96, 'train_mean_loss': 0.7439835659992962, 'train_sum_loss': 232.8668561577797, 'val_mae': 5.99, 'val_r2': -41.87, 'val_spearmanr': 0.45, 'val_mse': 39.35, 'val_rmse': 6.27, 'val_mean_loss': 5.992888749217073, 'val_sum_loss': 1875.7741785049438},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_6338e068_2_hidden_dimension=256,dropout=0.5000,times=6,base_learning_rate=0.0010_2024-03-27_15-38-02',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.71, 'train_r2': 0.03, 'train_spearmanr': 0.57, 'train_mse': 0.84, 'train_rmse': 0.92, 'train_mean_loss': 0.7091067884676754, 'train_sum_loss': 221.95042479038239, 'val_mae': 2.08, 'val_r2': -5.45, 'val_spearmanr': 0.28, 'val_mse': 5.92, 'val_rmse': 2.43, 'val_mean_loss': 2.0828685855713136, 'val_sum_loss': 651.9378672838211},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_1a4f9c1a_3_hidden_dimension=64,dropout=0.5000,times=3,base_learning_rate=0.0000_2024-03-27_15-38-07',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 5.33, 'train_r2': -33.14, 'train_spearmanr': 0.01, 'train_mse': 29.62, 'train_rmse': 5.44, 'train_mean_loss': 5.32672552255015, 'train_sum_loss': 1667.265088558197, 'val_mae': 4.11, 'val_r2': -18.16, 'val_spearmanr': 0.55, 'val_mse': 17.59, 'val_rmse': 4.19, 'val_mean_loss': 4.1111377664267446, 'val_sum_loss': 1286.786120891571},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_c8e09ba1_4_hidden_dimension=64,dropout=0.5000,times=6,base_learning_rate=0.0000_2024-03-27_15-38-12',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.26, 'train_r2': 0.83, 'train_spearmanr': 0.92, 'train_mse': 0.15, 'train_rmse': 0.38, 'train_mean_loss': 0.2648915268552189, 'train_sum_loss': 82.91104790568352, 'val_mae': 0.34, 'val_r2': 0.74, 'val_spearmanr': 0.88, 'val_mse': 0.23, 'val_rmse': 0.48, 'val_mean_loss': 0.34096498392260494, 'val_sum_loss': 106.72203996777534},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_19088fc4_5_hidden_dimension=64,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_15-38-18',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.71, 'train_r2': 0.04, 'train_spearmanr': 0.55, 'train_mse': 0.84, 'train_rmse': 0.91, 'train_mean_loss': 0.7108150254994535, 'train_sum_loss': 222.48510298132896, 'val_mae': 3.72, 'val_r2': -15.91, 'val_spearmanr': 0.45, 'val_mse': 15.52, 'val_rmse': 3.94, 'val_mean_loss': 3.718591543813102, 'val_sum_loss': 1163.919153213501},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_98a15140_6_hidden_dimension=256,dropout=0.5000,times=3,base_learning_rate=0.0010_2024-03-27_15-49-18',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 1.34, 'train_r2': -2.36, 'train_spearmanr': 0.21, 'train_mse': 2.91, 'train_rmse': 1.71, 'train_mean_loss': 1.343040972471999, 'train_sum_loss': 420.37182438373566, 'val_mae': 6.73, 'val_r2': -54.75, 'val_spearmanr': 0.21, 'val_mse': 51.17, 'val_rmse': 7.15, 'val_mean_loss': 6.725017869053557, 'val_sum_loss': 2104.9305930137634},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_067afa6f_7_hidden_dimension=256,dropout=0.5000,times=10,base_learning_rate=0.0001_2024-03-27_15-49-34',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 2.59, 'train_r2': -10.53, 'train_spearmanr': 0.12, 'train_mse': 10.01, 'train_rmse': 3.16, 'train_mean_loss': 2.5912451108042807, 'train_sum_loss': 811.0597196817398, 'val_mae': 3.23, 'val_r2': -15.58, 'val_spearmanr': 0.33, 'val_mse': 15.22, 'val_rmse': 3.9, 'val_mean_loss': 3.2327590659022714, 'val_sum_loss': 1011.8535876274109},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_45c87e9f_8_hidden_dimension=256,dropout=0.2000,times=10,base_learning_rate=0.0000_2024-03-27_15-55-36',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.42, 'train_r2': 0.63, 'train_spearmanr': 0.81, 'train_mse': 0.32, 'train_rmse': 0.57, 'train_mean_loss': 0.4207765416215403, 'train_sum_loss': 131.70305752754211, 'val_mae': 0.52, 'val_r2': 0.44, 'val_spearmanr': 0.84, 'val_mse': 0.51, 'val_rmse': 0.72, 'val_mean_loss': 0.5177384744436977, 'val_sum_loss': 162.05214250087738},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_a73eb169_9_hidden_dimension=64,dropout=0.2000,times=6,base_learning_rate=0.0001_2024-03-27_16-07-10',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 1.14, 'train_r2': -1.5, 'train_spearmanr': 0.35, 'train_mse': 2.17, 'train_rmse': 1.47, 'train_mean_loss': 1.1389849020269351, 'train_sum_loss': 356.5022743344307, 'val_mae': 5.6, 'val_r2': -36.17, 'val_spearmanr': 0.46, 'val_mse': 34.12, 'val_rmse': 5.84, 'val_mean_loss': 5.599347576165733, 'val_sum_loss': 1752.5957913398743},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_2332ba89_10_hidden_dimension=256,dropout=0.5000,times=3,base_learning_rate=0.0000_2024-03-27_16-13-22',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.54, 'train_r2': 0.41, 'train_spearmanr': 0.69, 'train_mse': 0.51, 'train_rmse': 0.72, 'train_mean_loss': 0.5449255942917479, 'train_sum_loss': 170.5617110133171, 'val_mae': 0.8, 'val_r2': -0.13, 'val_spearmanr': 0.75, 'val_mse': 1.04, 'val_rmse': 1.02, 'val_mean_loss': 0.7958055685122554, 'val_sum_loss': 249.08714294433594},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_17f7921f_11_hidden_dimension=256,dropout=0.2000,times=10,base_learning_rate=0.0010_2024-03-27_16-31-58',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 5.33, 'train_r2': -33.14, 'train_spearmanr': 0.01, 'train_mse': 29.62, 'train_rmse': 5.44, 'train_mean_loss': 5.32676584956745, 'train_sum_loss': 1667.2777109146118, 'val_mae': 4.11, 'val_r2': -18.16, 'val_spearmanr': 0.54, 'val_mse': 17.59, 'val_rmse': 4.19, 'val_mean_loss': 4.110791903334304, 'val_sum_loss': 1286.677865743637},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_3e6f253b_12_hidden_dimension=128,dropout=0.5000,times=6,base_learning_rate=0.0000_2024-03-27_16-34-19',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.3, 'train_r2': 0.79, 'train_spearmanr': 0.89, 'train_mse': 0.18, 'train_rmse': 0.43, 'train_mean_loss': 0.30407341057881, 'train_sum_loss': 95.17497751116753, 'val_mae': 0.34, 'val_r2': 0.73, 'val_spearmanr': 0.88, 'val_mse': 0.25, 'val_rmse': 0.5, 'val_mean_loss': 0.3399337810544541, 'val_sum_loss': 106.39927347004414},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_83fd788f_13_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0010_2024-03-27_16-46-03',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.54, 'train_r2': 0.4, 'train_spearmanr': 0.7, 'train_mse': 0.52, 'train_rmse': 0.72, 'train_mean_loss': 0.5367235769859899, 'train_sum_loss': 167.99447959661484, 'val_mae': 0.74, 'val_r2': 0.03, 'val_spearmanr': 0.81, 'val_mse': 0.89, 'val_rmse': 0.94, 'val_mean_loss': 0.7372109004483817, 'val_sum_loss': 230.74701184034348},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_14cf76cb_14_hidden_dimension=128,dropout=0.2000,times=10,base_learning_rate=0.0001_2024-03-27_17-25-39',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.84, 'train_r2': -0.41, 'train_spearmanr': 0.5, 'train_mse': 1.22, 'train_rmse': 1.1, 'train_mean_loss': 0.835504373422446, 'train_sum_loss': 261.5128688812256, 'val_mae': 1.86, 'val_r2': -4.04, 'val_spearmanr': 0.61, 'val_mse': 4.63, 'val_rmse': 2.15, 'val_mean_loss': 1.8587724873052238, 'val_sum_loss': 581.795788526535},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_908b48e6_15_hidden_dimension=128,dropout=0.2000,times=3,base_learning_rate=0.0000_2024-03-27_17-43-09',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.22, 'train_r2': 0.88, 'train_spearmanr': 0.94, 'train_mse': 0.1, 'train_rmse': 0.32, 'train_mean_loss': 0.2185977080854745, 'train_sum_loss': 68.42108263075352, 'val_mae': 0.33, 'val_r2': 0.74, 'val_spearmanr': 0.88, 'val_mse': 0.23, 'val_rmse': 0.48, 'val_mean_loss': 0.3350976157588319, 'val_sum_loss': 104.88555373251438},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_bf29bc12_16_hidden_dimension=256,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-27_17-43-27',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 5.38, 'train_r2': -33.65, 'train_spearmanr': -0.01, 'train_mse': 30.06, 'train_rmse': 5.48, 'train_mean_loss': 5.379987238314205, 'train_sum_loss': 1683.9360055923462, 'val_mae': 4.14, 'val_r2': -18.57, 'val_spearmanr': 0.27, 'val_mse': 17.96, 'val_rmse': 4.24, 'val_mean_loss': 4.1383551979979005, 'val_sum_loss': 1295.305176973343},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_8f21dfca_17_hidden_dimension=64,dropout=0.5000,times=10,base_learning_rate=0.0000_2024-03-27_17-48-06',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 5.33, 'train_r2': -33.14, 'train_spearmanr': 0.01, 'train_mse': 29.62, 'train_rmse': 5.44, 'train_mean_loss': 5.326730085257143, 'train_sum_loss': 1667.2665166854858, 'val_mae': 4.11, 'val_r2': -18.15, 'val_spearmanr': 0.55, 'val_mse': 17.58, 'val_rmse': 4.19, 'val_mean_loss': 4.109576772196224, 'val_sum_loss': 1286.2975296974182},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_e4097f41_18_hidden_dimension=256,dropout=0.5000,times=6,base_learning_rate=0.0000_2024-03-27_18-02-51',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.46, 'train_r2': 0.55, 'train_spearmanr': 0.77, 'train_mse': 0.39, 'train_rmse': 0.62, 'train_mean_loss': 0.46397148686856887, 'train_sum_loss': 145.22307538986206, 'val_mae': 0.96, 'val_r2': -0.28, 'val_spearmanr': 0.81, 'val_mse': 1.17, 'val_rmse': 1.08, 'val_mean_loss': 0.9643136931303591, 'val_sum_loss': 301.8301859498024},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_86691537_19_hidden_dimension=128,dropout=0.0000,times=6,base_learning_rate=0.0010_2024-03-27_18-07-03',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.34, 'train_r2': 0.74, 'train_spearmanr': 0.87, 'train_mse': 0.23, 'train_rmse': 0.48, 'train_mean_loss': 0.34344194410517576, 'train_sum_loss': 107.49732850492, 'val_mae': 0.35, 'val_r2': 0.72, 'val_spearmanr': 0.87, 'val_mse': 0.26, 'val_rmse': 0.51, 'val_mean_loss': 0.347747804924322, 'val_sum_loss': 108.84506294131279},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_05d19e47_20_hidden_dimension=256,dropout=0.2000,times=6,base_learning_rate=0.0010_2024-03-27_18-14-57',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.26, 'train_r2': 0.83, 'train_spearmanr': 0.92, 'train_mse': 0.14, 'train_rmse': 0.38, 'train_mean_loss': 0.26303990199543037, 'train_sum_loss': 82.3314893245697, 'val_mae': 0.34, 'val_r2': 0.75, 'val_spearmanr': 0.88, 'val_mse': 0.23, 'val_rmse': 0.48, 'val_mean_loss': 0.33555597328720765, 'val_sum_loss': 105.02901963889599},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_4f46e9a2_21_hidden_dimension=64,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_18-21-05',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.22, 'train_r2': 0.88, 'train_spearmanr': 0.94, 'train_mse': 0.1, 'train_rmse': 0.32, 'train_mean_loss': 0.21823431727604364, 'train_sum_loss': 68.30734130740166, 'val_mae': 0.34, 'val_r2': 0.74, 'val_spearmanr': 0.88, 'val_mse': 0.24, 'val_rmse': 0.49, 'val_mean_loss': 0.33797757637005643, 'val_sum_loss': 105.78698140382767},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_f15d9f3f_22_hidden_dimension=64,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-27_18-42-00',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.46, 'train_r2': 0.56, 'train_spearmanr': 0.77, 'train_mse': 0.38, 'train_rmse': 0.62, 'train_mean_loss': 0.4629214476948729, 'train_sum_loss': 144.89441312849522, 'val_mae': 0.51, 'val_r2': 0.48, 'val_spearmanr': 0.83, 'val_mse': 0.48, 'val_rmse': 0.69, 'val_mean_loss': 0.5095475433162227, 'val_sum_loss': 159.48838105797768},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_6f77aa7a_23_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0010_2024-03-27_18-53-42',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.26, 'train_r2': 0.83, 'train_spearmanr': 0.92, 'train_mse': 0.14, 'train_rmse': 0.38, 'train_mean_loss': 0.26397785625328274, 'train_sum_loss': 82.62506900727749, 'val_mae': 0.34, 'val_r2': 0.75, 'val_spearmanr': 0.88, 'val_mse': 0.23, 'val_rmse': 0.48, 'val_mean_loss': 0.33896798600023165, 'val_sum_loss': 106.09697961807251},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_6077fa19_24_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_19-13-01',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.27, 'train_r2': 0.83, 'train_spearmanr': 0.92, 'train_mse': 0.15, 'train_rmse': 0.38, 'train_mean_loss': 0.265727419679919, 'train_sum_loss': 83.17268235981464, 'val_mae': 0.34, 'val_r2': 0.75, 'val_spearmanr': 0.88, 'val_mse': 0.23, 'val_rmse': 0.48, 'val_mean_loss': 0.33940037475607265, 'val_sum_loss': 106.23231729865074},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_b7d6cfa8_25_hidden_dimension=64,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_20-31-50',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.6, 'train_r2': 0.29, 'train_spearmanr': 0.67, 'train_mse': 0.62, 'train_rmse': 0.79, 'train_mean_loss': 0.6004612078301061, 'train_sum_loss': 187.9443580508232, 'val_mae': 0.7, 'val_r2': 0.05, 'val_spearmanr': 0.72, 'val_mse': 0.87, 'val_rmse': 0.93, 'val_mean_loss': 0.6965301491962835, 'val_sum_loss': 218.01393669843674},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_38c16ad5_26_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0010_2024-03-27_21-26-10',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.47, 'train_r2': 0.55, 'train_spearmanr': 0.77, 'train_mse': 0.39, 'train_rmse': 0.62, 'train_mean_loss': 0.4719738937414492, 'train_sum_loss': 147.7278287410736, 'val_mae': 0.47, 'val_r2': 0.53, 'val_spearmanr': 0.79, 'val_mse': 0.43, 'val_rmse': 0.65, 'val_mean_loss': 0.4685977430294116, 'val_sum_loss': 146.67109356820583},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_175cae67_27_hidden_dimension=128,dropout=0.0000,times=6,base_learning_rate=0.0010_2024-03-27_21-31-08',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.22, 'train_r2': 0.88, 'train_spearmanr': 0.94, 'train_mse': 0.1, 'train_rmse': 0.32, 'train_mean_loss': 0.2184523101241444, 'train_sum_loss': 68.3755730688572, 'val_mae': 0.34, 'val_r2': 0.74, 'val_spearmanr': 0.88, 'val_mse': 0.24, 'val_rmse': 0.49, 'val_mean_loss': 0.33894972208018503, 'val_sum_loss': 106.09126301109791},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_968d6b19_28_hidden_dimension=128,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-27_21-33-13',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.33, 'train_r2': 0.76, 'train_spearmanr': 0.88, 'train_mse': 0.21, 'train_rmse': 0.46, 'train_mean_loss': 0.33291799391801363, 'train_sum_loss': 104.20333209633827, 'val_mae': 0.4, 'val_r2': 0.65, 'val_spearmanr': 0.85, 'val_mse': 0.32, 'val_rmse': 0.57, 'val_mean_loss': 0.4030913667747388, 'val_sum_loss': 126.16759780049324},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_049ccfc2_29_hidden_dimension=256,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-27_22-01-40',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.26, 'train_r2': 0.83, 'train_spearmanr': 0.92, 'train_mse': 0.15, 'train_rmse': 0.38, 'train_mean_loss': 0.26493940909449665, 'train_sum_loss': 82.92603504657745, 'val_mae': 0.34, 'val_r2': 0.74, 'val_spearmanr': 0.88, 'val_mse': 0.24, 'val_rmse': 0.49, 'val_mean_loss': 0.33874873383738363, 'val_sum_loss': 106.02835369110107},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_953ca32a_30_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_22-06-25',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.47, 'train_r2': 0.55, 'train_spearmanr': 0.78, 'train_mse': 0.39, 'train_rmse': 0.62, 'train_mean_loss': 0.46525421443457804, 'train_sum_loss': 145.62456911802292, 'val_mae': 0.47, 'val_r2': 0.56, 'val_spearmanr': 0.81, 'val_mse': 0.4, 'val_rmse': 0.63, 'val_mean_loss': 0.46908274826150353, 'val_sum_loss': 146.8229002058506},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_c2958242_31_hidden_dimension=256,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-27_22-29-22',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.45, 'train_r2': 0.58, 'train_spearmanr': 0.78, 'train_mse': 0.36, 'train_rmse': 0.6, 'train_mean_loss': 0.4500239771395065, 'train_sum_loss': 140.85750484466553, 'val_mae': 0.47, 'val_r2': 0.57, 'val_spearmanr': 0.78, 'val_mse': 0.4, 'val_rmse': 0.63, 'val_mean_loss': 0.4716618437165269, 'val_sum_loss': 147.63015708327293},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_a8b75a46_32_hidden_dimension=64,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_22-46-59',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.46, 'train_r2': 0.57, 'train_spearmanr': 0.79, 'train_mse': 0.38, 'train_rmse': 0.61, 'train_mean_loss': 0.4575188710285833, 'train_sum_loss': 143.20340663194656, 'val_mae': 0.52, 'val_r2': 0.43, 'val_spearmanr': 0.78, 'val_mse': 0.52, 'val_rmse': 0.72, 'val_mean_loss': 0.5195376087491885, 'val_sum_loss': 162.61527153849602},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_62b48c25_33_hidden_dimension=64,dropout=0.0000,times=10,base_learning_rate=0.0001_2024-03-27_23-02-29',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.63, 'train_r2': 0.18, 'train_spearmanr': 0.64, 'train_mse': 0.71, 'train_rmse': 0.84, 'train_mean_loss': 0.6332195180292708, 'train_sum_loss': 198.19770914316177, 'val_mae': 0.67, 'val_r2': 0.13, 'val_spearmanr': 0.58, 'val_mse': 0.8, 'val_rmse': 0.89, 'val_mean_loss': 0.6659153968381425, 'val_sum_loss': 208.4315192103386},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_7cbcfbbc_34_hidden_dimension=256,dropout=0.0000,times=6,base_learning_rate=0.0010_2024-03-27_23-06-05',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.45, 'train_r2': 0.59, 'train_spearmanr': 0.79, 'train_mse': 0.36, 'train_rmse': 0.6, 'train_mean_loss': 0.44522994337752225, 'train_sum_loss': 139.35697227716446, 'val_mae': 0.46, 'val_r2': 0.59, 'val_spearmanr': 0.8, 'val_mse': 0.38, 'val_rmse': 0.61, 'val_mean_loss': 0.46322251689700655, 'val_sum_loss': 144.98864778876305},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_8c89365c_35_hidden_dimension=64,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-27_23-17-40',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.34, 'train_r2': 0.75, 'train_spearmanr': 0.88, 'train_mse': 0.21, 'train_rmse': 0.46, 'train_mean_loss': 0.3396813504326458, 'train_sum_loss': 106.32026268541813, 'val_mae': 0.41, 'val_r2': 0.64, 'val_spearmanr': 0.85, 'val_mse': 0.33, 'val_rmse': 0.57, 'val_mean_loss': 0.4083416013957593, 'val_sum_loss': 127.81092123687267},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_92b3f729_36_hidden_dimension=64,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-27_23-37-00',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.45, 'train_r2': 0.58, 'train_spearmanr': 0.79, 'train_mse': 0.36, 'train_rmse': 0.6, 'train_mean_loss': 0.4492305814743804, 'train_sum_loss': 140.60917200148106, 'val_mae': 0.59, 'val_r2': 0.34, 'val_spearmanr': 0.84, 'val_mse': 0.61, 'val_rmse': 0.78, 'val_mean_loss': 0.5922249235665075, 'val_sum_loss': 185.36640107631683},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_36222233_37_hidden_dimension=256,dropout=0.0000,times=3,base_learning_rate=0.0010_2024-03-27_23-41-58',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.44, 'train_r2': 0.59, 'train_spearmanr': 0.8, 'train_mse': 0.36, 'train_rmse': 0.6, 'train_mean_loss': 0.44524128025713056, 'train_sum_loss': 139.36052072048187, 'val_mae': 0.46, 'val_r2': 0.54, 'val_spearmanr': 0.83, 'val_mse': 0.42, 'val_rmse': 0.65, 'val_mean_loss': 0.46305171150369007, 'val_sum_loss': 144.93518570065498},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_b7d79026_38_hidden_dimension=64,dropout=0.0000,times=10,base_learning_rate=0.0001_2024-03-27_23-55-20',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.86, 'train_r2': -0.49, 'train_spearmanr': 0.47, 'train_mse': 1.29, 'train_rmse': 1.14, 'train_mean_loss': 0.8570244834065056, 'train_sum_loss': 268.24866330623627, 'val_mae': 1.75, 'val_r2': -3.54, 'val_spearmanr': 0.59, 'val_mse': 4.17, 'val_rmse': 2.04, 'val_mean_loss': 1.7481543895916436, 'val_sum_loss': 547.1723239421844},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_56e81361_39_hidden_dimension=64,dropout=0.2000,times=6,base_learning_rate=0.0001_2024-03-28_00-00-53',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 1.2, 'train_r2': -1.63, 'train_spearmanr': 0.25, 'train_mse': 2.28, 'train_rmse': 1.51, 'train_mean_loss': 1.1994055043013332, 'train_sum_loss': 375.4139228463173, 'val_mae': 8.01, 'val_r2': -74.55, 'val_spearmanr': 0.3, 'val_mse': 69.35, 'val_rmse': 8.33, 'val_mean_loss': 8.009335219288786, 'val_sum_loss': 2506.92192363739},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_62b97141_40_hidden_dimension=256,dropout=0.5000,times=6,base_learning_rate=0.0001_2024-03-28_00-12-25',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.67, 'train_r2': 0.11, 'train_spearmanr': 0.6, 'train_mse': 0.77, 'train_rmse': 0.88, 'train_mean_loss': 0.6715192207322714, 'train_sum_loss': 210.18551608920097, 'val_mae': 0.63, 'val_r2': 0.22, 'val_spearmanr': 0.6, 'val_mse': 0.71, 'val_rmse': 0.84, 'val_mean_loss': 0.6319996746012959, 'val_sum_loss': 197.8158981502056},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_4d1a9d5c_41_hidden_dimension=256,dropout=0.0000,times=3,base_learning_rate=0.0001_2024-03-28_00-16-05',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.91, 'train_r2': -0.68, 'train_spearmanr': 0.46, 'train_mse': 1.46, 'train_rmse': 1.21, 'train_mean_loss': 0.9116126022780665, 'train_sum_loss': 285.3347445130348, 'val_mae': 1.87, 'val_r2': -4.34, 'val_spearmanr': 0.63, 'val_mse': 4.9, 'val_rmse': 2.21, 'val_mean_loss': 1.8677897738953368, 'val_sum_loss': 584.6181992292404},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_efd8d8e3_42_hidden_dimension=64,dropout=0.2000,times=3,base_learning_rate=0.0001_2024-03-28_00-22-51',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 5.38, 'train_r2': -33.65, 'train_spearmanr': -0.01, 'train_mse': 30.06, 'train_rmse': 5.48, 'train_mean_loss': 5.380033343744735, 'train_sum_loss': 1683.950436592102, 'val_mae': 4.14, 'val_r2': -18.55, 'val_spearmanr': 0.27, 'val_mse': 17.95, 'val_rmse': 4.24, 'val_mean_loss': 4.136402242099896, 'val_sum_loss': 1294.6939017772675},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_2174919c_43_hidden_dimension=256,dropout=0.5000,times=10,base_learning_rate=0.0000_2024-03-28_00-23-51',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.66, 'train_r2': 0.12, 'train_spearmanr': 0.62, 'train_mse': 0.76, 'train_rmse': 0.87, 'train_mean_loss': 0.6570274945074758, 'train_sum_loss': 205.64960578083992, 'val_mae': 0.71, 'val_r2': 0.03, 'val_spearmanr': 0.48, 'val_mse': 0.89, 'val_rmse': 0.95, 'val_mean_loss': 0.7121136932136913, 'val_sum_loss': 222.8915859758854},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_86b86616_44_hidden_dimension=64,dropout=0.0000,times=6,base_learning_rate=0.0001_2024-03-28_00-29-38',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.86, 'train_r2': -0.47, 'train_spearmanr': 0.47, 'train_mse': 1.28, 'train_rmse': 1.13, 'train_mean_loss': 0.8573960334348222, 'train_sum_loss': 268.36495846509933, 'val_mae': 1.77, 'val_r2': -3.77, 'val_spearmanr': 0.56, 'val_mse': 4.38, 'val_rmse': 2.09, 'val_mean_loss': 1.772541850138777, 'val_sum_loss': 554.8055990934372},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_aa8d30c4_45_hidden_dimension=256,dropout=0.2000,times=6,base_learning_rate=0.0001_2024-03-28_00-41-35',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.75, 'train_r2': -0.06, 'train_spearmanr': 0.48, 'train_mse': 0.92, 'train_rmse': 0.96, 'train_mean_loss': 0.7494499655767751, 'train_sum_loss': 234.57783922553062, 'val_mae': 4.95, 'val_r2': -28.93, 'val_spearmanr': 0.43, 'val_mse': 27.47, 'val_rmse': 5.24, 'val_mean_loss': 4.953839000421591, 'val_sum_loss': 1550.551607131958},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_efec30f0_46_hidden_dimension=128,dropout=0.5000,times=10,base_learning_rate=0.0010_2024-03-28_00-42-24',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 0.62, 'train_r2': 0.25, 'train_spearmanr': 0.65, 'train_mse': 0.65, 'train_rmse': 0.81, 'train_mean_loss': 0.616405230360671, 'train_sum_loss': 192.93483710289001, 'val_mae': 0.66, 'val_r2': 0.14, 'val_spearmanr': 0.76, 'val_mse': 0.79, 'val_rmse': 0.89, 'val_mean_loss': 0.6628475111132612, 'val_sum_loss': 207.47127097845078},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_26898e90_47_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0010_2024-03-28_00-49-40',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 1.67, 'train_r2': -4.66, 'train_spearmanr': 0.17, 'train_mse': 4.91, 'train_rmse': 2.22, 'train_mean_loss': 1.669723980152569, 'train_sum_loss': 522.6236057877541, 'val_mae': 1.32, 'val_r2': -2.59, 'val_spearmanr': 0.35, 'val_mse': 3.29, 'val_rmse': 1.81, 'val_mean_loss': 1.3246175593461473, 'val_sum_loss': 414.6052960753441},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_bca28bd5_48_hidden_dimension=128,dropout=0.0000,times=3,base_learning_rate=0.0000_2024-03-28_00-53-19',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 1.35, 'train_r2': -2.37, 'train_spearmanr': 0.21, 'train_mse': 2.93, 'train_rmse': 1.71, 'train_mean_loss': 1.3482016317379741, 'train_sum_loss': 421.9871107339859, 'val_mae': 6.61, 'val_r2': -53.07, 'val_spearmanr': 0.2, 'val_mse': 49.63, 'val_rmse': 7.04, 'val_mean_loss': 6.608816127045848, 'val_sum_loss': 2068.5594477653503},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_6b12052d_49_hidden_dimension=128,dropout=0.5000,times=10,base_learning_rate=0.0001_2024-03-28_00-56-17',\n    filesystem='local',\n    checkpoint=None\n  ),\n  Result(\n    metrics={'train_mae': 2.4, 'train_r2': -9.79, 'train_spearmanr': 0.06, 'train_mse': 9.36, 'train_rmse': 3.06, 'train_mean_loss': 2.4022798564868233, 'train_sum_loss': 751.9135950803757, 'val_mae': 2.01, 'val_r2': -6.37, 'val_spearmanr': 0.06, 'val_mse': 6.76, 'val_rmse': 2.6, 'val_mean_loss': 2.013023229833609, 'val_sum_loss': 630.0762709379196},\n    path='C:/Users/johan/ray_results/trainable_function_2024-03-27_15-37-53/trainable_function_aa45c608_50_hidden_dimension=64,dropout=0.2000,times=3,base_learning_rate=0.0000_2024-03-28_00-59-59',\n    filesystem='local',\n    checkpoint=None\n  )\n]>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:52:29.219075Z",
     "end_time": "2024-03-28T06:52:29.232075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    train_mae  train_r2  train_spearmanr  train_mse  train_rmse  \\\n0        0.66      0.16             0.59   0.730000        0.86   \n1        0.74     -0.06             0.49   0.920000        0.96   \n2        0.71      0.03             0.57   0.840000        0.92   \n3        5.33    -33.14             0.01  29.620001        5.44   \n4        0.26      0.83             0.92   0.150000        0.38   \n5        0.71      0.04             0.55   0.840000        0.91   \n6        1.34     -2.36             0.21   2.910000        1.71   \n7        2.59    -10.53             0.12  10.010000        3.16   \n8        0.42      0.63             0.81   0.320000        0.57   \n9        1.14     -1.50             0.35   2.170000        1.47   \n10       0.54      0.41             0.69   0.510000        0.72   \n11       5.33    -33.14             0.01  29.620001        5.44   \n12       0.30      0.79             0.89   0.180000        0.43   \n13       0.54      0.40             0.70   0.520000        0.72   \n14       0.84     -0.41             0.50   1.220000        1.10   \n15       0.22      0.88             0.94   0.100000        0.32   \n16       5.38    -33.65            -0.01  30.059999        5.48   \n17       5.33    -33.14             0.01  29.620001        5.44   \n18       0.46      0.55             0.77   0.390000        0.62   \n19       0.34      0.74             0.87   0.230000        0.48   \n20       0.26      0.83             0.92   0.140000        0.38   \n21       0.22      0.88             0.94   0.100000        0.32   \n22       0.46      0.56             0.77   0.380000        0.62   \n23       0.26      0.83             0.92   0.140000        0.38   \n24       0.27      0.83             0.92   0.150000        0.38   \n25       0.60      0.29             0.67   0.620000        0.79   \n26       0.47      0.55             0.77   0.390000        0.62   \n27       0.22      0.88             0.94   0.100000        0.32   \n28       0.33      0.76             0.88   0.210000        0.46   \n29       0.26      0.83             0.92   0.150000        0.38   \n30       0.47      0.55             0.78   0.390000        0.62   \n31       0.45      0.58             0.78   0.360000        0.60   \n32       0.46      0.57             0.79   0.380000        0.61   \n33       0.63      0.18             0.64   0.710000        0.84   \n34       0.45      0.59             0.79   0.360000        0.60   \n35       0.34      0.75             0.88   0.210000        0.46   \n36       0.45      0.58             0.79   0.360000        0.60   \n37       0.44      0.59             0.80   0.360000        0.60   \n38       0.86     -0.49             0.47   1.290000        1.14   \n39       1.20     -1.63             0.25   2.280000        1.51   \n40       0.67      0.11             0.60   0.770000        0.88   \n41       0.91     -0.68             0.46   1.460000        1.21   \n42       5.38    -33.65            -0.01  30.059999        5.48   \n43       0.66      0.12             0.62   0.760000        0.87   \n44       0.86     -0.47             0.47   1.280000        1.13   \n45       0.75     -0.06             0.48   0.920000        0.96   \n46       0.62      0.25             0.65   0.650000        0.81   \n47       1.67     -4.66             0.17   4.910000        2.22   \n48       1.35     -2.37             0.21   2.930000        1.71   \n49       2.40     -9.79             0.06   9.360000        3.06   \n\n    train_mean_loss  train_sum_loss  val_mae  val_r2  val_spearmanr  ...  \\\n0          0.661960      207.193606     1.52   -2.81           0.32  ...   \n1          0.743984      232.866856     5.99  -41.87           0.45  ...   \n2          0.709107      221.950425     2.08   -5.45           0.28  ...   \n3          5.326726     1667.265089     4.11  -18.16           0.55  ...   \n4          0.264892       82.911048     0.34    0.74           0.88  ...   \n5          0.710815      222.485103     3.72  -15.91           0.45  ...   \n6          1.343041      420.371824     6.73  -54.75           0.21  ...   \n7          2.591245      811.059720     3.23  -15.58           0.33  ...   \n8          0.420777      131.703058     0.52    0.44           0.84  ...   \n9          1.138985      356.502274     5.60  -36.17           0.46  ...   \n10         0.544926      170.561711     0.80   -0.13           0.75  ...   \n11         5.326766     1667.277711     4.11  -18.16           0.54  ...   \n12         0.304073       95.174978     0.34    0.73           0.88  ...   \n13         0.536724      167.994480     0.74    0.03           0.81  ...   \n14         0.835504      261.512869     1.86   -4.04           0.61  ...   \n15         0.218598       68.421083     0.33    0.74           0.88  ...   \n16         5.379987     1683.936006     4.14  -18.57           0.27  ...   \n17         5.326730     1667.266517     4.11  -18.15           0.55  ...   \n18         0.463971      145.223075     0.96   -0.28           0.81  ...   \n19         0.343442      107.497329     0.35    0.72           0.87  ...   \n20         0.263040       82.331489     0.34    0.75           0.88  ...   \n21         0.218234       68.307341     0.34    0.74           0.88  ...   \n22         0.462921      144.894413     0.51    0.48           0.83  ...   \n23         0.263978       82.625069     0.34    0.75           0.88  ...   \n24         0.265727       83.172682     0.34    0.75           0.88  ...   \n25         0.600461      187.944358     0.70    0.05           0.72  ...   \n26         0.471974      147.727829     0.47    0.53           0.79  ...   \n27         0.218452       68.375573     0.34    0.74           0.88  ...   \n28         0.332918      104.203332     0.40    0.65           0.85  ...   \n29         0.264939       82.926035     0.34    0.74           0.88  ...   \n30         0.465254      145.624569     0.47    0.56           0.81  ...   \n31         0.450024      140.857505     0.47    0.57           0.78  ...   \n32         0.457519      143.203407     0.52    0.43           0.78  ...   \n33         0.633220      198.197709     0.67    0.13           0.58  ...   \n34         0.445230      139.356972     0.46    0.59           0.80  ...   \n35         0.339681      106.320263     0.41    0.64           0.85  ...   \n36         0.449231      140.609172     0.59    0.34           0.84  ...   \n37         0.445241      139.360521     0.46    0.54           0.83  ...   \n38         0.857024      268.248663     1.75   -3.54           0.59  ...   \n39         1.199406      375.413923     8.01  -74.55           0.30  ...   \n40         0.671519      210.185516     0.63    0.22           0.60  ...   \n41         0.911613      285.334745     1.87   -4.34           0.63  ...   \n42         5.380033     1683.950437     4.14  -18.55           0.27  ...   \n43         0.657027      205.649606     0.71    0.03           0.48  ...   \n44         0.857396      268.364958     1.77   -3.77           0.56  ...   \n45         0.749450      234.577839     4.95  -28.93           0.43  ...   \n46         0.616405      192.934837     0.66    0.14           0.76  ...   \n47         1.669724      522.623606     1.32   -2.59           0.35  ...   \n48         1.348202      421.987111     6.61  -53.07           0.20  ...   \n49         2.402280      751.913595     2.01   -6.37           0.06  ...   \n\n      pid      hostname    node_ip  time_since_restore  \\\n0   71072  AT-MB-PC-E13  127.0.0.1         7524.538136   \n1    7540  AT-MB-PC-E13  127.0.0.1          670.638888   \n2   72652  AT-MB-PC-E13  127.0.0.1         3366.604872   \n3   51252  AT-MB-PC-E13  127.0.0.1          675.815035   \n4   53176  AT-MB-PC-E13  127.0.0.1         7485.012967   \n5    7540  AT-MB-PC-E13  127.0.0.1          377.838681   \n6   51252  AT-MB-PC-E13  127.0.0.1         1056.588029   \n7    7540  AT-MB-PC-E13  127.0.0.1         1066.522432   \n8   51252  AT-MB-PC-E13  127.0.0.1         6055.525805   \n9    7540  AT-MB-PC-E13  127.0.0.1         1115.319124   \n10   7540  AT-MB-PC-E13  127.0.0.1         3221.174881   \n11  72652  AT-MB-PC-E13  127.0.0.1          703.627758   \n12  72652  AT-MB-PC-E13  127.0.0.1         7658.614059   \n13   7540  AT-MB-PC-E13  127.0.0.1         3325.803578   \n14  53176  AT-MB-PC-E13  127.0.0.1         1181.348377   \n15  71072  AT-MB-PC-E13  127.0.0.1        13660.882941   \n16  51252  AT-MB-PC-E13  127.0.0.1         1136.542742   \n17  53176  AT-MB-PC-E13  127.0.0.1          725.859102   \n18  51252  AT-MB-PC-E13  127.0.0.1         2096.751661   \n19  53176  AT-MB-PC-E13  127.0.0.1        13603.012081   \n20   7540  AT-MB-PC-E13  127.0.0.1         7843.890280   \n21  51252  AT-MB-PC-E13  127.0.0.1        13641.622192   \n22  72652  AT-MB-PC-E13  127.0.0.1         1158.837035   \n23  72652  AT-MB-PC-E13  127.0.0.1         7988.183711   \n24   7540  AT-MB-PC-E13  127.0.0.1         8108.829556   \n25  72652  AT-MB-PC-E13  127.0.0.1          422.561398   \n26  71072  AT-MB-PC-E13  127.0.0.1         2116.629879   \n27  72652  AT-MB-PC-E13  127.0.0.1        13157.555536   \n28  53176  AT-MB-PC-E13  127.0.0.1         6017.129664   \n29  71072  AT-MB-PC-E13  127.0.0.1         7778.799373   \n30  51252  AT-MB-PC-E13  127.0.0.1         1986.540921   \n31   7540  AT-MB-PC-E13  127.0.0.1         1145.490482   \n32  51252  AT-MB-PC-E13  127.0.0.1         3170.531125   \n33   7540  AT-MB-PC-E13  127.0.0.1          694.841182   \n34   7540  AT-MB-PC-E13  127.0.0.1         1159.941559   \n35   7540  AT-MB-PC-E13  127.0.0.1         5729.504404   \n36  53176  AT-MB-PC-E13  127.0.0.1         1135.083896   \n37  51252  AT-MB-PC-E13  127.0.0.1         3260.452007   \n38  53176  AT-MB-PC-E13  127.0.0.1          691.928914   \n39  53176  AT-MB-PC-E13  127.0.0.1          685.618794   \n40  71072  AT-MB-PC-E13  127.0.0.1          406.009350   \n41  71072  AT-MB-PC-E13  127.0.0.1          407.116924   \n42  53176  AT-MB-PC-E13  127.0.0.1         1112.853240   \n43  71072  AT-MB-PC-E13  127.0.0.1          716.676235   \n44  71072  AT-MB-PC-E13  127.0.0.1          703.917979   \n45  53176  AT-MB-PC-E13  127.0.0.1         1088.228886   \n46  51252  AT-MB-PC-E13  127.0.0.1          396.297044   \n47  71072  AT-MB-PC-E13  127.0.0.1          399.565867   \n48  51252  AT-MB-PC-E13  127.0.0.1          824.144242   \n49  71072  AT-MB-PC-E13  127.0.0.1          337.342743   \n\n    iterations_since_restore config/model/hidden_dimension  \\\n0                        100                            64   \n1                          5                           256   \n2                         45                            64   \n3                          5                            64   \n4                        100                            64   \n5                          5                           256   \n6                          5                           256   \n7                          5                           256   \n8                         45                            64   \n9                         15                           256   \n10                        15                           256   \n11                         5                           128   \n12                       100                           128   \n13                        15                           128   \n14                        15                           128   \n15                       100                           256   \n16                         5                            64   \n17                         5                           256   \n18                        15                           128   \n19                       100                           256   \n20                       100                            64   \n21                       100                            64   \n22                        15                           128   \n23                       100                           128   \n24                       100                            64   \n25                         5                           128   \n26                        15                           128   \n27                       100                           128   \n28                        45                           256   \n29                       100                           128   \n30                        15                           256   \n31                        15                            64   \n32                        15                            64   \n33                         5                           256   \n34                        15                            64   \n35                        45                            64   \n36                        15                           256   \n37                        15                            64   \n38                         5                            64   \n39                         5                           256   \n40                         5                           256   \n41                         5                            64   \n42                         5                           256   \n43                         5                            64   \n44                         5                           256   \n45                         5                           128   \n46                         5                           128   \n47                         5                           128   \n48                         5                           128   \n49                         5                            64   \n\n    config/model/modules/1/times  config/model/modules/1/parameter/dropout  \\\n0                              3                                       0.5   \n1                              6                                       0.5   \n2                              3                                       0.5   \n3                              6                                       0.5   \n4                              3                                       0.0   \n5                              3                                       0.5   \n6                             10                                       0.5   \n7                             10                                       0.2   \n8                              6                                       0.2   \n9                              3                                       0.5   \n10                            10                                       0.2   \n11                             6                                       0.5   \n12                             3                                       0.0   \n13                            10                                       0.2   \n14                             3                                       0.2   \n15                             6                                       0.0   \n16                            10                                       0.5   \n17                             6                                       0.5   \n18                             6                                       0.0   \n19                             6                                       0.2   \n20                             3                                       0.0   \n21                             6                                       0.0   \n22                             3                                       0.0   \n23                             3                                       0.0   \n24                             3                                       0.0   \n25                             3                                       0.0   \n26                             6                                       0.0   \n27                             6                                       0.0   \n28                             6                                       0.0   \n29                             3                                       0.0   \n30                             6                                       0.0   \n31                             3                                       0.0   \n32                            10                                       0.0   \n33                             6                                       0.0   \n34                             3                                       0.0   \n35                             6                                       0.0   \n36                             3                                       0.0   \n37                            10                                       0.0   \n38                             6                                       0.2   \n39                             6                                       0.5   \n40                             3                                       0.0   \n41                             3                                       0.2   \n42                            10                                       0.5   \n43                             6                                       0.0   \n44                             6                                       0.2   \n45                            10                                       0.5   \n46                             3                                       0.0   \n47                             3                                       0.0   \n48                            10                                       0.5   \n49                             3                                       0.2   \n\n   config/optimizer/base_learning_rate    logdir  \n0                              0.00001  9728a09d  \n1                              0.00100  6338e068  \n2                              0.00001  1a4f9c1a  \n3                              0.00001  c8e09ba1  \n4                              0.00010  19088fc4  \n5                              0.00100  98a15140  \n6                              0.00010  067afa6f  \n7                              0.00001  45c87e9f  \n8                              0.00010  a73eb169  \n9                              0.00001  2332ba89  \n10                             0.00100  17f7921f  \n11                             0.00001  3e6f253b  \n12                             0.00100  83fd788f  \n13                             0.00010  14cf76cb  \n14                             0.00001  908b48e6  \n15                             0.00010  bf29bc12  \n16                             0.00001  8f21dfca  \n17                             0.00001  e4097f41  \n18                             0.00100  86691537  \n19                             0.00100  05d19e47  \n20                             0.00010  4f46e9a2  \n21                             0.00010  f15d9f3f  \n22                             0.00100  6f77aa7a  \n23                             0.00010  6077fa19  \n24                             0.00010  b7d6cfa8  \n25                             0.00100  38c16ad5  \n26                             0.00100  175cae67  \n27                             0.00010  968d6b19  \n28                             0.00010  049ccfc2  \n29                             0.00010  953ca32a  \n30                             0.00010  c2958242  \n31                             0.00010  a8b75a46  \n32                             0.00010  62b48c25  \n33                             0.00100  7cbcfbbc  \n34                             0.00010  8c89365c  \n35                             0.00010  92b3f729  \n36                             0.00100  36222233  \n37                             0.00010  b7d79026  \n38                             0.00010  56e81361  \n39                             0.00010  62b97141  \n40                             0.00010  4d1a9d5c  \n41                             0.00010  efd8d8e3  \n42                             0.00001  2174919c  \n43                             0.00010  86b86616  \n44                             0.00010  aa8d30c4  \n45                             0.00100  efec30f0  \n46                             0.00100  26898e90  \n47                             0.00001  bca28bd5  \n48                             0.00010  6b12052d  \n49                             0.00001  aa45c608  \n\n[50 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_mae</th>\n      <th>train_r2</th>\n      <th>train_spearmanr</th>\n      <th>train_mse</th>\n      <th>train_rmse</th>\n      <th>train_mean_loss</th>\n      <th>train_sum_loss</th>\n      <th>val_mae</th>\n      <th>val_r2</th>\n      <th>val_spearmanr</th>\n      <th>...</th>\n      <th>pid</th>\n      <th>hostname</th>\n      <th>node_ip</th>\n      <th>time_since_restore</th>\n      <th>iterations_since_restore</th>\n      <th>config/model/hidden_dimension</th>\n      <th>config/model/modules/1/times</th>\n      <th>config/model/modules/1/parameter/dropout</th>\n      <th>config/optimizer/base_learning_rate</th>\n      <th>logdir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.66</td>\n      <td>0.16</td>\n      <td>0.59</td>\n      <td>0.730000</td>\n      <td>0.86</td>\n      <td>0.661960</td>\n      <td>207.193606</td>\n      <td>1.52</td>\n      <td>-2.81</td>\n      <td>0.32</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>7524.538136</td>\n      <td>100</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>9728a09d</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.74</td>\n      <td>-0.06</td>\n      <td>0.49</td>\n      <td>0.920000</td>\n      <td>0.96</td>\n      <td>0.743984</td>\n      <td>232.866856</td>\n      <td>5.99</td>\n      <td>-41.87</td>\n      <td>0.45</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>670.638888</td>\n      <td>5</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.5</td>\n      <td>0.00100</td>\n      <td>6338e068</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.71</td>\n      <td>0.03</td>\n      <td>0.57</td>\n      <td>0.840000</td>\n      <td>0.92</td>\n      <td>0.709107</td>\n      <td>221.950425</td>\n      <td>2.08</td>\n      <td>-5.45</td>\n      <td>0.28</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>3366.604872</td>\n      <td>45</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>1a4f9c1a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.33</td>\n      <td>-33.14</td>\n      <td>0.01</td>\n      <td>29.620001</td>\n      <td>5.44</td>\n      <td>5.326726</td>\n      <td>1667.265089</td>\n      <td>4.11</td>\n      <td>-18.16</td>\n      <td>0.55</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>675.815035</td>\n      <td>5</td>\n      <td>64</td>\n      <td>6</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>c8e09ba1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.26</td>\n      <td>0.83</td>\n      <td>0.92</td>\n      <td>0.150000</td>\n      <td>0.38</td>\n      <td>0.264892</td>\n      <td>82.911048</td>\n      <td>0.34</td>\n      <td>0.74</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>7485.012967</td>\n      <td>100</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>19088fc4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.71</td>\n      <td>0.04</td>\n      <td>0.55</td>\n      <td>0.840000</td>\n      <td>0.91</td>\n      <td>0.710815</td>\n      <td>222.485103</td>\n      <td>3.72</td>\n      <td>-15.91</td>\n      <td>0.45</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>377.838681</td>\n      <td>5</td>\n      <td>256</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>0.00100</td>\n      <td>98a15140</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.34</td>\n      <td>-2.36</td>\n      <td>0.21</td>\n      <td>2.910000</td>\n      <td>1.71</td>\n      <td>1.343041</td>\n      <td>420.371824</td>\n      <td>6.73</td>\n      <td>-54.75</td>\n      <td>0.21</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1056.588029</td>\n      <td>5</td>\n      <td>256</td>\n      <td>10</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n      <td>067afa6f</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.59</td>\n      <td>-10.53</td>\n      <td>0.12</td>\n      <td>10.010000</td>\n      <td>3.16</td>\n      <td>2.591245</td>\n      <td>811.059720</td>\n      <td>3.23</td>\n      <td>-15.58</td>\n      <td>0.33</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1066.522432</td>\n      <td>5</td>\n      <td>256</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.00001</td>\n      <td>45c87e9f</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.42</td>\n      <td>0.63</td>\n      <td>0.81</td>\n      <td>0.320000</td>\n      <td>0.57</td>\n      <td>0.420777</td>\n      <td>131.703058</td>\n      <td>0.52</td>\n      <td>0.44</td>\n      <td>0.84</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>6055.525805</td>\n      <td>45</td>\n      <td>64</td>\n      <td>6</td>\n      <td>0.2</td>\n      <td>0.00010</td>\n      <td>a73eb169</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.14</td>\n      <td>-1.50</td>\n      <td>0.35</td>\n      <td>2.170000</td>\n      <td>1.47</td>\n      <td>1.138985</td>\n      <td>356.502274</td>\n      <td>5.60</td>\n      <td>-36.17</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1115.319124</td>\n      <td>15</td>\n      <td>256</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>2332ba89</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.54</td>\n      <td>0.41</td>\n      <td>0.69</td>\n      <td>0.510000</td>\n      <td>0.72</td>\n      <td>0.544926</td>\n      <td>170.561711</td>\n      <td>0.80</td>\n      <td>-0.13</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>3221.174881</td>\n      <td>15</td>\n      <td>256</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.00100</td>\n      <td>17f7921f</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5.33</td>\n      <td>-33.14</td>\n      <td>0.01</td>\n      <td>29.620001</td>\n      <td>5.44</td>\n      <td>5.326766</td>\n      <td>1667.277711</td>\n      <td>4.11</td>\n      <td>-18.16</td>\n      <td>0.54</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>703.627758</td>\n      <td>5</td>\n      <td>128</td>\n      <td>6</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>3e6f253b</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.30</td>\n      <td>0.79</td>\n      <td>0.89</td>\n      <td>0.180000</td>\n      <td>0.43</td>\n      <td>0.304073</td>\n      <td>95.174978</td>\n      <td>0.34</td>\n      <td>0.73</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>7658.614059</td>\n      <td>100</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>83fd788f</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.54</td>\n      <td>0.40</td>\n      <td>0.70</td>\n      <td>0.520000</td>\n      <td>0.72</td>\n      <td>0.536724</td>\n      <td>167.994480</td>\n      <td>0.74</td>\n      <td>0.03</td>\n      <td>0.81</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>3325.803578</td>\n      <td>15</td>\n      <td>128</td>\n      <td>10</td>\n      <td>0.2</td>\n      <td>0.00010</td>\n      <td>14cf76cb</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.84</td>\n      <td>-0.41</td>\n      <td>0.50</td>\n      <td>1.220000</td>\n      <td>1.10</td>\n      <td>0.835504</td>\n      <td>261.512869</td>\n      <td>1.86</td>\n      <td>-4.04</td>\n      <td>0.61</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1181.348377</td>\n      <td>15</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.2</td>\n      <td>0.00001</td>\n      <td>908b48e6</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.22</td>\n      <td>0.88</td>\n      <td>0.94</td>\n      <td>0.100000</td>\n      <td>0.32</td>\n      <td>0.218598</td>\n      <td>68.421083</td>\n      <td>0.33</td>\n      <td>0.74</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>13660.882941</td>\n      <td>100</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>bf29bc12</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5.38</td>\n      <td>-33.65</td>\n      <td>-0.01</td>\n      <td>30.059999</td>\n      <td>5.48</td>\n      <td>5.379987</td>\n      <td>1683.936006</td>\n      <td>4.14</td>\n      <td>-18.57</td>\n      <td>0.27</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1136.542742</td>\n      <td>5</td>\n      <td>64</td>\n      <td>10</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>8f21dfca</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5.33</td>\n      <td>-33.14</td>\n      <td>0.01</td>\n      <td>29.620001</td>\n      <td>5.44</td>\n      <td>5.326730</td>\n      <td>1667.266517</td>\n      <td>4.11</td>\n      <td>-18.15</td>\n      <td>0.55</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>725.859102</td>\n      <td>5</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>e4097f41</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.46</td>\n      <td>0.55</td>\n      <td>0.77</td>\n      <td>0.390000</td>\n      <td>0.62</td>\n      <td>0.463971</td>\n      <td>145.223075</td>\n      <td>0.96</td>\n      <td>-0.28</td>\n      <td>0.81</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>2096.751661</td>\n      <td>15</td>\n      <td>128</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>86691537</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.34</td>\n      <td>0.74</td>\n      <td>0.87</td>\n      <td>0.230000</td>\n      <td>0.48</td>\n      <td>0.343442</td>\n      <td>107.497329</td>\n      <td>0.35</td>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>13603.012081</td>\n      <td>100</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.2</td>\n      <td>0.00100</td>\n      <td>05d19e47</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.26</td>\n      <td>0.83</td>\n      <td>0.92</td>\n      <td>0.140000</td>\n      <td>0.38</td>\n      <td>0.263040</td>\n      <td>82.331489</td>\n      <td>0.34</td>\n      <td>0.75</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>7843.890280</td>\n      <td>100</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>4f46e9a2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.22</td>\n      <td>0.88</td>\n      <td>0.94</td>\n      <td>0.100000</td>\n      <td>0.32</td>\n      <td>0.218234</td>\n      <td>68.307341</td>\n      <td>0.34</td>\n      <td>0.74</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>13641.622192</td>\n      <td>100</td>\n      <td>64</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>f15d9f3f</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.46</td>\n      <td>0.56</td>\n      <td>0.77</td>\n      <td>0.380000</td>\n      <td>0.62</td>\n      <td>0.462921</td>\n      <td>144.894413</td>\n      <td>0.51</td>\n      <td>0.48</td>\n      <td>0.83</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1158.837035</td>\n      <td>15</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>6f77aa7a</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.26</td>\n      <td>0.83</td>\n      <td>0.92</td>\n      <td>0.140000</td>\n      <td>0.38</td>\n      <td>0.263978</td>\n      <td>82.625069</td>\n      <td>0.34</td>\n      <td>0.75</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>7988.183711</td>\n      <td>100</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>6077fa19</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.27</td>\n      <td>0.83</td>\n      <td>0.92</td>\n      <td>0.150000</td>\n      <td>0.38</td>\n      <td>0.265727</td>\n      <td>83.172682</td>\n      <td>0.34</td>\n      <td>0.75</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>8108.829556</td>\n      <td>100</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>b7d6cfa8</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.60</td>\n      <td>0.29</td>\n      <td>0.67</td>\n      <td>0.620000</td>\n      <td>0.79</td>\n      <td>0.600461</td>\n      <td>187.944358</td>\n      <td>0.70</td>\n      <td>0.05</td>\n      <td>0.72</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>422.561398</td>\n      <td>5</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>38c16ad5</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.47</td>\n      <td>0.55</td>\n      <td>0.77</td>\n      <td>0.390000</td>\n      <td>0.62</td>\n      <td>0.471974</td>\n      <td>147.727829</td>\n      <td>0.47</td>\n      <td>0.53</td>\n      <td>0.79</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>2116.629879</td>\n      <td>15</td>\n      <td>128</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>175cae67</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.22</td>\n      <td>0.88</td>\n      <td>0.94</td>\n      <td>0.100000</td>\n      <td>0.32</td>\n      <td>0.218452</td>\n      <td>68.375573</td>\n      <td>0.34</td>\n      <td>0.74</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>72652</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>13157.555536</td>\n      <td>100</td>\n      <td>128</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>968d6b19</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.33</td>\n      <td>0.76</td>\n      <td>0.88</td>\n      <td>0.210000</td>\n      <td>0.46</td>\n      <td>0.332918</td>\n      <td>104.203332</td>\n      <td>0.40</td>\n      <td>0.65</td>\n      <td>0.85</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>6017.129664</td>\n      <td>45</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>049ccfc2</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.26</td>\n      <td>0.83</td>\n      <td>0.92</td>\n      <td>0.150000</td>\n      <td>0.38</td>\n      <td>0.264939</td>\n      <td>82.926035</td>\n      <td>0.34</td>\n      <td>0.74</td>\n      <td>0.88</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>7778.799373</td>\n      <td>100</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>953ca32a</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.47</td>\n      <td>0.55</td>\n      <td>0.78</td>\n      <td>0.390000</td>\n      <td>0.62</td>\n      <td>0.465254</td>\n      <td>145.624569</td>\n      <td>0.47</td>\n      <td>0.56</td>\n      <td>0.81</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1986.540921</td>\n      <td>15</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>c2958242</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.45</td>\n      <td>0.58</td>\n      <td>0.78</td>\n      <td>0.360000</td>\n      <td>0.60</td>\n      <td>0.450024</td>\n      <td>140.857505</td>\n      <td>0.47</td>\n      <td>0.57</td>\n      <td>0.78</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1145.490482</td>\n      <td>15</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>a8b75a46</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.46</td>\n      <td>0.57</td>\n      <td>0.79</td>\n      <td>0.380000</td>\n      <td>0.61</td>\n      <td>0.457519</td>\n      <td>143.203407</td>\n      <td>0.52</td>\n      <td>0.43</td>\n      <td>0.78</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>3170.531125</td>\n      <td>15</td>\n      <td>64</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>62b48c25</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.63</td>\n      <td>0.18</td>\n      <td>0.64</td>\n      <td>0.710000</td>\n      <td>0.84</td>\n      <td>0.633220</td>\n      <td>198.197709</td>\n      <td>0.67</td>\n      <td>0.13</td>\n      <td>0.58</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>694.841182</td>\n      <td>5</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>7cbcfbbc</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.45</td>\n      <td>0.59</td>\n      <td>0.79</td>\n      <td>0.360000</td>\n      <td>0.60</td>\n      <td>0.445230</td>\n      <td>139.356972</td>\n      <td>0.46</td>\n      <td>0.59</td>\n      <td>0.80</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1159.941559</td>\n      <td>15</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>8c89365c</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.34</td>\n      <td>0.75</td>\n      <td>0.88</td>\n      <td>0.210000</td>\n      <td>0.46</td>\n      <td>0.339681</td>\n      <td>106.320263</td>\n      <td>0.41</td>\n      <td>0.64</td>\n      <td>0.85</td>\n      <td>...</td>\n      <td>7540</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>5729.504404</td>\n      <td>45</td>\n      <td>64</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>92b3f729</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.45</td>\n      <td>0.58</td>\n      <td>0.79</td>\n      <td>0.360000</td>\n      <td>0.60</td>\n      <td>0.449231</td>\n      <td>140.609172</td>\n      <td>0.59</td>\n      <td>0.34</td>\n      <td>0.84</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1135.083896</td>\n      <td>15</td>\n      <td>256</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>36222233</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.44</td>\n      <td>0.59</td>\n      <td>0.80</td>\n      <td>0.360000</td>\n      <td>0.60</td>\n      <td>0.445241</td>\n      <td>139.360521</td>\n      <td>0.46</td>\n      <td>0.54</td>\n      <td>0.83</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>3260.452007</td>\n      <td>15</td>\n      <td>64</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>b7d79026</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.86</td>\n      <td>-0.49</td>\n      <td>0.47</td>\n      <td>1.290000</td>\n      <td>1.14</td>\n      <td>0.857024</td>\n      <td>268.248663</td>\n      <td>1.75</td>\n      <td>-3.54</td>\n      <td>0.59</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>691.928914</td>\n      <td>5</td>\n      <td>64</td>\n      <td>6</td>\n      <td>0.2</td>\n      <td>0.00010</td>\n      <td>56e81361</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1.20</td>\n      <td>-1.63</td>\n      <td>0.25</td>\n      <td>2.280000</td>\n      <td>1.51</td>\n      <td>1.199406</td>\n      <td>375.413923</td>\n      <td>8.01</td>\n      <td>-74.55</td>\n      <td>0.30</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>685.618794</td>\n      <td>5</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n      <td>62b97141</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.67</td>\n      <td>0.11</td>\n      <td>0.60</td>\n      <td>0.770000</td>\n      <td>0.88</td>\n      <td>0.671519</td>\n      <td>210.185516</td>\n      <td>0.63</td>\n      <td>0.22</td>\n      <td>0.60</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>406.009350</td>\n      <td>5</td>\n      <td>256</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>4d1a9d5c</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.91</td>\n      <td>-0.68</td>\n      <td>0.46</td>\n      <td>1.460000</td>\n      <td>1.21</td>\n      <td>0.911613</td>\n      <td>285.334745</td>\n      <td>1.87</td>\n      <td>-4.34</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>407.116924</td>\n      <td>5</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.2</td>\n      <td>0.00010</td>\n      <td>efd8d8e3</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>5.38</td>\n      <td>-33.65</td>\n      <td>-0.01</td>\n      <td>30.059999</td>\n      <td>5.48</td>\n      <td>5.380033</td>\n      <td>1683.950437</td>\n      <td>4.14</td>\n      <td>-18.55</td>\n      <td>0.27</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1112.853240</td>\n      <td>5</td>\n      <td>256</td>\n      <td>10</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n      <td>2174919c</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.66</td>\n      <td>0.12</td>\n      <td>0.62</td>\n      <td>0.760000</td>\n      <td>0.87</td>\n      <td>0.657027</td>\n      <td>205.649606</td>\n      <td>0.71</td>\n      <td>0.03</td>\n      <td>0.48</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>716.676235</td>\n      <td>5</td>\n      <td>64</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n      <td>86b86616</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.86</td>\n      <td>-0.47</td>\n      <td>0.47</td>\n      <td>1.280000</td>\n      <td>1.13</td>\n      <td>0.857396</td>\n      <td>268.364958</td>\n      <td>1.77</td>\n      <td>-3.77</td>\n      <td>0.56</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>703.917979</td>\n      <td>5</td>\n      <td>256</td>\n      <td>6</td>\n      <td>0.2</td>\n      <td>0.00010</td>\n      <td>aa8d30c4</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.75</td>\n      <td>-0.06</td>\n      <td>0.48</td>\n      <td>0.920000</td>\n      <td>0.96</td>\n      <td>0.749450</td>\n      <td>234.577839</td>\n      <td>4.95</td>\n      <td>-28.93</td>\n      <td>0.43</td>\n      <td>...</td>\n      <td>53176</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>1088.228886</td>\n      <td>5</td>\n      <td>128</td>\n      <td>10</td>\n      <td>0.5</td>\n      <td>0.00100</td>\n      <td>efec30f0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.62</td>\n      <td>0.25</td>\n      <td>0.65</td>\n      <td>0.650000</td>\n      <td>0.81</td>\n      <td>0.616405</td>\n      <td>192.934837</td>\n      <td>0.66</td>\n      <td>0.14</td>\n      <td>0.76</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>396.297044</td>\n      <td>5</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00100</td>\n      <td>26898e90</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1.67</td>\n      <td>-4.66</td>\n      <td>0.17</td>\n      <td>4.910000</td>\n      <td>2.22</td>\n      <td>1.669724</td>\n      <td>522.623606</td>\n      <td>1.32</td>\n      <td>-2.59</td>\n      <td>0.35</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>399.565867</td>\n      <td>5</td>\n      <td>128</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n      <td>bca28bd5</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1.35</td>\n      <td>-2.37</td>\n      <td>0.21</td>\n      <td>2.930000</td>\n      <td>1.71</td>\n      <td>1.348202</td>\n      <td>421.987111</td>\n      <td>6.61</td>\n      <td>-53.07</td>\n      <td>0.20</td>\n      <td>...</td>\n      <td>51252</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>824.144242</td>\n      <td>5</td>\n      <td>128</td>\n      <td>10</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n      <td>6b12052d</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>2.40</td>\n      <td>-9.79</td>\n      <td>0.06</td>\n      <td>9.360000</td>\n      <td>3.06</td>\n      <td>2.402280</td>\n      <td>751.913595</td>\n      <td>2.01</td>\n      <td>-6.37</td>\n      <td>0.06</td>\n      <td>...</td>\n      <td>71072</td>\n      <td>AT-MB-PC-E13</td>\n      <td>127.0.0.1</td>\n      <td>337.342743</td>\n      <td>5</td>\n      <td>64</td>\n      <td>3</td>\n      <td>0.2</td>\n      <td>0.00001</td>\n      <td>aa45c608</td>\n    </tr>\n  </tbody>\n</table>\n<p>50 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:52:30.824093Z",
     "end_time": "2024-03-28T06:52:30.869930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_45552\\2168251635.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mdfs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics_dataframe\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;31m# Plot by epoch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m  \u001B[1;31m# This plots everything on the same plot\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdfs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval_accuracy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0max\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0max\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlegend\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\Masterarbeit_PTGNN\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6200\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6201\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6202\u001B[0m         ):\n\u001B[0;32m   6203\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6204\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "dfs = {result.path: result.metrics_dataframe for result in results}\n",
    "# Plot by epoch\n",
    "ax = None  # This plots everything on the same plot\n",
    "for d in dfs.values():\n",
    "    ax = d.val_accuracy.plot(ax=ax, legend=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-27T14:00:16.615441Z",
     "end_time": "2024-03-27T14:00:16.824548Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Storing results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'output_dir': 'results/ba_chienn',\n 'config_files': ['configs/hyper_param_opt/subsetting.yaml',\n  'configs/datasets/binding_affinity.yaml',\n  'configs/models/chienn.yaml',\n  'configs/general.yaml'],\n 'search_space': {'model': {'hidden_dimension': 'tune.choice([64, 128, 256])',\n   'modules': {1: {'times': 'tune.choice([3, 6, 10])',\n     'parameter': {'dropout': 'tune.choice([0.0, 0.2, 0.5])'}}}},\n  'optimizer': {'base_learning_rate': 'tune.choice([0.001, 0.0001, 0.00001])'}},\n 'hyper_settings': {'scheduler': {'grace_period': 5,\n   'reduction_factor': 3,\n   'brackets': 1},\n  'max_concurrent_trials': 5,\n  'num_samples': 50}}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fetching config file\n",
    "benchmark_config = import_as(\"configs/hyper_param_opt/benchmark_instructions_bindingaffinity_chienn.yaml\")\n",
    "display(benchmark_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:18.283116Z",
     "end_time": "2024-03-28T06:53:18.294625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "output_path = benchmark_config['output_dir']\n",
    "\n",
    "# make sure that output_dir exists\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:24.368596Z",
     "end_time": "2024-03-28T06:53:24.379598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'subset_size': 10000,\n  'dataset': {'type': 'ba',\n   'mask_chiral_tasks': True,\n   'single_conformer': True,\n   'single_enantiomer': False},\n  'loader': {'general': {'n_neighbors_in_circle': 3,\n    'batch_size': 32,\n    'num_workers': 0},\n   'train': {'sampler': 'full_batch'},\n   'val': {'sampler': 'full_batch'},\n   'test': {'sampler': 'full_batch'}}},\n 'training': {'loss_function': 'l1',\n  'optimization_metric': 'mae',\n  'optimization_metric_mode': 'min',\n  'task_type': 'regression',\n  'n_max_epochs': 100,\n  'clip_grad_norm': True},\n 'model': {'out_dim': 1,\n  'mode': 'custom',\n  'hidden_dim': 128,\n  'modules': {0: {'type': 'graph_embedding',\n    'parameter': {'node_type': 'linear', 'edge_type': 'linear'}},\n   1: {'type': 'gps_layer',\n    'parameter': {'local_model': 'chienn', 'local_model_params': {}},\n    'times': 5}},\n  'head': {'type': 'san_head', 'n_layer': 3, 'pool_function': 'add'}},\n 'optimizer': {'type': 'adam_w',\n  'base_learning_rate': 0.001,\n  'weight_decay': 1e-05},\n 'scheduler': {'type': 'cosine_with_warmup',\n  'num_warmup_epochs': 10,\n  'max_epochs': 100}}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_config = load_and_merge_default_configs(\n",
    "    benchmark_config['config_files']\n",
    ")\n",
    "display(default_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:28.896438Z",
     "end_time": "2024-03-28T06:53:28.927997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# create absolute path to root dict that is not hyper-opt-run specific\n",
    "default_config['data']['dataset']['root'] = os.path.abspath(\n",
    "    os.path.join(\"src\", default_config['data']['dataset']['type'])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:30.457868Z",
     "end_time": "2024-03-28T06:53:30.471867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# currently limit number of epochs\n",
    "default_config['training']['n_max_epochs'] = 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:30.950863Z",
     "end_time": "2024-03-28T06:53:30.958931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'subset_size': 10000,\n  'dataset': {'type': 'ba',\n   'mask_chiral_tasks': True,\n   'single_conformer': True,\n   'single_enantiomer': False,\n   'root': 'D:\\\\DATEN\\\\Masterarbeit_PTGNN\\\\notebooks\\\\hyperoptimization\\\\src\\\\ba'},\n  'loader': {'general': {'n_neighbors_in_circle': 3,\n    'batch_size': 32,\n    'num_workers': 0},\n   'train': {'sampler': 'full_batch'},\n   'val': {'sampler': 'full_batch'},\n   'test': {'sampler': 'full_batch'}}},\n 'training': {'loss_function': 'l1',\n  'optimization_metric': 'mae',\n  'optimization_metric_mode': 'min',\n  'task_type': 'regression',\n  'n_max_epochs': 3,\n  'clip_grad_norm': True},\n 'model': {'out_dim': 1,\n  'mode': 'custom',\n  'hidden_dim': 128,\n  'modules': {0: {'type': 'graph_embedding',\n    'parameter': {'node_type': 'linear', 'edge_type': 'linear'}},\n   1: {'type': 'gps_layer',\n    'parameter': {'local_model': 'chienn', 'local_model_params': {}},\n    'times': 5}},\n  'head': {'type': 'san_head', 'n_layer': 3, 'pool_function': 'add'}},\n 'optimizer': {'type': 'adam_w',\n  'base_learning_rate': 0.001,\n  'weight_decay': 1e-05},\n 'scheduler': {'type': 'cosine_with_warmup',\n  'num_warmup_epochs': 10,\n  'max_epochs': 100}}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(default_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:31.975468Z",
     "end_time": "2024-03-28T06:53:31.985636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# save general configs\n",
    "export_as(default_config, os.path.join(output_path, \"general_config.yaml\"), save_type='yaml')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:34.050334Z",
     "end_time": "2024-03-28T06:53:34.073333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# save results dataframe\n",
    "results.get_dataframe().to_csv(os.path.join(output_path, \"results.csv\"), index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:35.134377Z",
     "end_time": "2024-03-28T06:53:35.161377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# for each trial save results\n",
    "for result in results:\n",
    "    # get metrics\n",
    "    trial_metrics = result.metrics_dataframe\n",
    "\n",
    "    # get trial id\n",
    "    trial_id = trial_metrics.trial_id[0]\n",
    "\n",
    "    # get config\n",
    "    trial_config = result.config\n",
    "\n",
    "    # saving\n",
    "    trial_metrics.to_csv(os.path.join(output_path, f\"{trial_id}.csv\"), index=None)\n",
    "    export_as(trial_config, os.path.join(output_path, f\"{trial_id}.yaml\"), save_type='yaml')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T06:53:35.992970Z",
     "end_time": "2024-03-28T06:53:36.076669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
