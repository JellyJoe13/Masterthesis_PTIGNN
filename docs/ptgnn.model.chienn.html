<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ptgnn.model.chienn package &mdash; Masterthesis - Permutation tree invariant graph neural networks and applications to molecular graphs with stereochemistry  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=92fd9be5" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ptgnn.model.framework package" href="ptgnn.model.framework.html" />
    <link rel="prev" title="ptgnn.model package" href="ptgnn.model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Masterthesis - Permutation tree invariant graph neural networks and applications to molecular graphs with stereochemistry
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="ptgnn.html">ptgnn</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="ptgnn.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ptgnn.dataset.html">ptgnn.dataset package</a></li>
<li class="toctree-l3"><a class="reference internal" href="ptgnn.features.html">ptgnn.features package</a></li>
<li class="toctree-l3"><a class="reference internal" href="ptgnn.loading.html">ptgnn.loading package</a></li>
<li class="toctree-l3"><a class="reference internal" href="ptgnn.masking.html">ptgnn.masking package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="ptgnn.model.html">ptgnn.model package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="ptgnn.model.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l5 current"><a class="current reference internal" href="#">ptgnn.model.chienn package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="#module-ptgnn.model.chienn.chienn_layer">ptgnn.model.chienn.chienn_layer module</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNAggregate"><code class="docutils literal notranslate"><span class="pre">ChiENNAggregate</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNAggregate.__init__"><code class="docutils literal notranslate"><span class="pre">ChiENNAggregate.__init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNAggregate.forward"><code class="docutils literal notranslate"><span class="pre">ChiENNAggregate.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNLayer"><code class="docutils literal notranslate"><span class="pre">ChiENNLayer</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNLayer.__init__"><code class="docutils literal notranslate"><span class="pre">ChiENNLayer.__init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNLayer.forward"><code class="docutils literal notranslate"><span class="pre">ChiENNLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNMessage"><code class="docutils literal notranslate"><span class="pre">ChiENNMessage</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNMessage.__init__"><code class="docutils literal notranslate"><span class="pre">ChiENNMessage.__init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_layer.ChiENNMessage.forward"><code class="docutils literal notranslate"><span class="pre">ChiENNMessage.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="#module-ptgnn.model.chienn.chienn_model">ptgnn.model.chienn.chienn_model module</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#ptgnn.model.chienn.chienn_model.ChiENNModel"><code class="docutils literal notranslate"><span class="pre">ChiENNModel</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_model.ChiENNModel.__init__"><code class="docutils literal notranslate"><span class="pre">ChiENNModel.__init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_model.ChiENNModel.forward"><code class="docutils literal notranslate"><span class="pre">ChiENNModel.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#ptgnn.model.chienn.chienn_model.GPSLayer"><code class="docutils literal notranslate"><span class="pre">GPSLayer</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_model.GPSLayer.__init__"><code class="docutils literal notranslate"><span class="pre">GPSLayer.__init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="#ptgnn.model.chienn.chienn_model.GPSLayer.forward"><code class="docutils literal notranslate"><span class="pre">GPSLayer.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="#module-ptgnn.model.chienn.utils">ptgnn.model.chienn.utils module</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#ptgnn.model.chienn.utils.build_embedding_layer"><code class="docutils literal notranslate"><span class="pre">build_embedding_layer()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="#module-ptgnn.model.chienn">Module contents</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="ptgnn.model.framework.html">ptgnn.model.framework package</a></li>
<li class="toctree-l5"><a class="reference internal" href="ptgnn.model.modules.html">ptgnn.model.modules package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ptgnn.model.html#module-ptgnn.model">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ptgnn.optimizing.html">ptgnn.optimizing package</a></li>
<li class="toctree-l3"><a class="reference internal" href="ptgnn.runtime_config.html">ptgnn.runtime_config package</a></li>
<li class="toctree-l3"><a class="reference internal" href="ptgnn.transform.html">ptgnn.transform package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ptgnn.html#module-ptgnn">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="experiments.html">experiments</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Masterthesis - Permutation tree invariant graph neural networks and applications to molecular graphs with stereochemistry</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">&lt;no title&gt;</a></li>
          <li class="breadcrumb-item"><a href="ptgnn.html">ptgnn</a></li>
          <li class="breadcrumb-item"><a href="ptgnn.model.html">ptgnn.model package</a></li>
      <li class="breadcrumb-item active">ptgnn.model.chienn package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/ptgnn.model.chienn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ptgnn-model-chienn-package">
<h1>ptgnn.model.chienn package<a class="headerlink" href="#ptgnn-model-chienn-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-ptgnn.model.chienn.chienn_layer">
<span id="ptgnn-model-chienn-chienn-layer-module"></span><h2>ptgnn.model.chienn.chienn_layer module<a class="headerlink" href="#module-ptgnn.model.chienn.chienn_layer" title="Link to this heading"></a></h2>
<p>The contents of this file are adapted from
<a class="reference external" href="https://github.com/gmum/ChiENN/blob/ee3185b39e8469a8caacf3d6d45a04c4a1cfff5b/chienn/model/chienn_layer.py">https://github.com/gmum/ChiENN/blob/ee3185b39e8469a8caacf3d6d45a04c4a1cfff5b/chienn/model/chienn_layer.py</a>
and serve the purpose of comparing this projects model to a pre-existing model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNAggregate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ptgnn.model.chienn.chienn_layer.</span></span><span class="sig-name descname"><span class="pre">ChiENNAggregate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_aggregation_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNAggregate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNAggregate" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>An aggregation module use in ChiENNLayer. It aggregates the messages from the incoming neighbors, the node itself
and the parallel node.</p>
<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNAggregate.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_aggregation_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNAggregate.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNAggregate.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_dim</strong> – hidden dimension of the model.</p></li>
<li><p><strong>self_embedding_name</strong> – a description of the embedding layer that will be applied to the node itself. Default
linear embedding is denoted by <cite>W_1</cite> matrix in the eq. (4).</p></li>
<li><p><strong>parallel_embedding_name</strong> – a description of the embedding layer that will be applied to the parallel node.
Default linear embedding is denoted by <cite>W_2</cite> matrix in the eq. (4).</p></li>
<li><p><strong>aggregation_name</strong> – aggregation of incoming messages. For the moment, only ‘sum’ is supported.</p></li>
<li><p><strong>post_aggregation_embedding_name</strong> – a description of the embedding layer that will be applied to the
aggregated messages. For simplicity, omitted in the paper.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNAggregate.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">msg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNAggregate.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNAggregate.forward" title="Link to this definition"></a></dt>
<dd><p>Aggregates the messages from the incoming neighbors, the node itself and the parallel node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – <p>a batch of data containing the following attributes:</p>
<ul>
<li><p>x: a tensor of shape (num_nodes, hidden_dim) containing the node features.</p></li>
<li><p>parallel_node_index: a tensor of shape (num_nodes,) containing the index of the parallel node.</p></li>
</ul>
</p></li>
<li><p><strong>msg</strong> – a tensor of shape (num_nodes, max_num_neighbors, hidden_dim) containing the order-sensitive messages.</p></li>
<li><p><strong>mask</strong> – a tensor of shape (num_nodes, max_num_neighbors) containing the mask for the messages.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a tensor of shape (num_nodes, hidden_dim) containing the aggregated messages.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ptgnn.model.chienn.chienn_layer.</span></span><span class="sig-name descname"><span class="pre">ChiENNLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_neighbors_embeddings_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">('linear',</span> <span class="pre">'linear',</span> <span class="pre">'linear')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">message_final_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ELU+linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_aggregation_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ELU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNLayer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>ChiENN layer that embeds the messages in a chiral-sensitive manner and aggregates them.
The implementation of the eq. (4) from the paper.</p>
<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_neighbors_embeddings_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">('linear',</span> <span class="pre">'linear',</span> <span class="pre">'linear')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">message_final_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ELU+linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_aggregation_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ELU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNLayer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNLayer.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_dim</strong> – hidden dimension of the model.</p></li>
<li><p><strong>k_neighbors_embeddings_names</strong> – a description of the embedding layers that will be used to embed the
k consecutive neighbors of each node. The length of this list determines the size of a window
sliding over the neighbors in the pre-computed order. Note that setting this to [‘linear’] * k
is equivalent to concatenating the embeddings of the k neighbors and pplying a linear layer to the
concatenated vector (as in the paper formulation). Default list describes the <cite>W_4</cite> matrix from the
eq. (4), while the length of the list corresponds <cite>k</cite>.</p></li>
<li><p><strong>message_final_embedding_name</strong> – a description of the embedding layer that will applied to the message obtained
from the k consecutive neighbors. Default <cite>ELU+linear</cite> embedding is denoted by <cite>W_3sigma</cite> in the eq. (4).</p></li>
<li><p><strong>self_embedding_name</strong> – a description of the embedding layer that will be applied to the node itself. Default
linear embedding is denoted by <cite>W_1</cite> matrix in the eq. (4).</p></li>
<li><p><strong>parallel_embedding_name</strong> – a description of the embedding layer that will be applied to the parallel node.
Default linear embedding is denoted by <cite>W_2</cite> matrix in the eq. (4).</p></li>
<li><p><strong>aggregation_name</strong> – aggregation of incoming messages. For the moment, only ‘sum’ is supported.</p></li>
<li><p><strong>post_aggregation_embedding_name</strong> – a description of the embedding layer that will be applied to the
aggregated messages. For simplicity, omitted in the paper.</p></li>
<li><p><strong>dropout</strong> – dropout probability.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNLayer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNLayer.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNMessage">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ptgnn.model.chienn.chienn_layer.</span></span><span class="sig-name descname"><span class="pre">ChiENNMessage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_neighbors_embeddings_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNMessage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNMessage" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A message module of ChiENN layer that embeds the messages in a chiral-sensitive manner.
The implementation of the k-ary message function <cite>psi^k</cite> from the eq. (4) from the paper.</p>
<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNMessage.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_neighbors_embeddings_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_embedding_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNMessage.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNMessage.__init__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_dim</strong> – hidden dimension of the model.</p></li>
<li><p><strong>k_neighbors_embeddings_names</strong> – a description of the embedding layers that will be used to embed the
k consecutive neighbors of each node. The length of this list determines the size of a window
sliding over the neighbors in the pre-computed order. Note that setting this to [‘linear’] * k
is equivalent to concatenating the embeddings of the k neighbors and pplying a linear layer to the
concatenated vector (as in the paper formulation). Default list describes the <cite>W_4</cite> matrix from the
eq. (4), while the length of the list corresponds <cite>k</cite>.</p></li>
<li><p><strong>final_embedding_name</strong> – a description of the embedding layer that will applied to the message obtained
from the k consecutive neighbors. Default <cite>ELU+linear</cite> embedding is denoted by <cite>W_3sigma</cite> in the eq. (4).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_layer.ChiENNMessage.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Batch</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_layer.html#ChiENNMessage.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_layer.ChiENNMessage.forward" title="Link to this definition"></a></dt>
<dd><p>Embeds the messages in a chiral-sensitive manner.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> – <p>a batch of data containing the following attributes:</p>
<ul class="simple">
<li><p><cite>x</cite> - node features of shape (num_nodes, hidden_dim).</p></li>
<li><dl class="simple">
<dt><cite>circle_index</cite> - a tensor of shape (num_nodes, circle_size) containing the indices of the</dt><dd><p>(non-parallel) neighbors in the pre-computed order. To simplify the implementation, the first (k-1)
indices for every atom are repeated, e.g. for k=3, the circle_index[0] may
be (i_1, i_2, i_3, …, i_n, i_1, i_2). Therefore, <cite>circle_size</cite> = <cite>max_num_neighbors</cite> + k-1.
The indices are padded with -1.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><cite>msg</cite> - a tensor of shape (num_nodes, max_num_neighbors, hidden_dim) containing the messages for each node.</p></li>
<li><p><cite>mask</cite> - a tensor of shape (num_nodes, max_num_neighbors) containing the neighbors mask for every node.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple of two tensors</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-ptgnn.model.chienn.chienn_model">
<span id="ptgnn-model-chienn-chienn-model-module"></span><h2>ptgnn.model.chienn.chienn_model module<a class="headerlink" href="#module-ptgnn.model.chienn.chienn_model" title="Link to this heading"></a></h2>
<p>The contents of this file are adapted from
<a class="reference external" href="https://github.com/gmum/ChiENN/blob/ee3185b39e8469a8caacf3d6d45a04c4a1cfff5b/chienn/model/chienn_model.py">https://github.com/gmum/ChiENN/blob/ee3185b39e8469a8caacf3d6d45a04c4a1cfff5b/chienn/model/chienn_model.py</a>
and serve the purpose of comparing this projects model to a pre-existing model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_model.ChiENNModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ptgnn.model.chienn.chienn_model.</span></span><span class="sig-name descname"><span class="pre">ChiENNModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">93</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_model.html#ChiENNModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_model.ChiENNModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A simplified version of the ChiENN model used in the experimental part of the paper. To make this implementation
concise and clear, we excluded computation of RWSE positional encodings. To reproduce the results from the paper,
use the <cite>experiments</cite> module. Note that this model behaves like GPSModel from experiments/graphgps/network.gps_model.py
with <cite>local_gnn_type</cite> set to <cite>ChiENN’ and `global_model_type</cite> set to <cite>None</cite> (except for the positional encodings).
Therefore, we wrapped <cite>ChiENNLayer</cite> with <cite>GPSLayer</cite>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_model.ChiENNModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">93</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_model.html#ChiENNModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_model.ChiENNModel.__init__" title="Link to this definition"></a></dt>
<dd><p>Init function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k_neighbors</strong> – number of k consecutive neighbors used to create a chiral-sensitive message. It’s <cite>k</cite> from
the eq. (4) in the paper.</p></li>
<li><p><strong>in_node_dim</strong> – number of input node features. Default (93) differs from the value used in the <cite>experiments</cite>
module (118) as here we explicitly excluded chiral tags, while in the <cite>experiments</cite> we masked them.</p></li>
<li><p><strong>out_dim</strong> – output dimension.</p></li>
<li><p><strong>n_layers</strong> – number of ChiENN layers.</p></li>
<li><p><strong>dropout</strong> – dropout probability.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_model.ChiENNModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Batch</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_model.html#ChiENNModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_model.ChiENNModel.forward" title="Link to this definition"></a></dt>
<dd><p>Run ChiENN model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> – <p>a batch representing <cite>batch_size</cite> graphs. Contains the following attributes:</p>
<ul class="simple">
<li><p>x: (num_nodes, hidden_dim) node features</p></li>
<li><p>batch (num_nodes,): batch indices of the nodes.</p></li>
<li><p>edge_index (2, num_edges): edge indices</p></li>
<li><p>circle_index (num_nodes, circle_size): indices of neighbors forming an order around a node.</p></li>
<li><p>parallel_node_index (num_nodes,): indices of parallel nodes.</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output of the shape (batch_size, out_dim).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_model.GPSLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ptgnn.model.chienn.chienn_model.</span></span><span class="sig-name descname"><span class="pre">GPSLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gnn_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_model.html#GPSLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_model.GPSLayer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A layer that wraps some GNN model and adds a residual connection and a MLP with batch normalization, similarly
to the GPSLayer from <cite>experiments/graphgps/layer/gps_layer.py</cite>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_model.GPSLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gnn_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_model.html#GPSLayer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_model.GPSLayer.__init__" title="Link to this definition"></a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ptgnn.model.chienn.chienn_model.GPSLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Batch</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/ptgnn/model/chienn/chienn_model.html#GPSLayer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.chienn_model.GPSLayer.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-ptgnn.model.chienn.utils">
<span id="ptgnn-model-chienn-utils-module"></span><h2>ptgnn.model.chienn.utils module<a class="headerlink" href="#module-ptgnn.model.chienn.utils" title="Link to this heading"></a></h2>
<p>The contents of this file are adapted from
<a class="reference external" href="https://github.com/gmum/ChiENN/blob/ee3185b39e8469a8caacf3d6d45a04c4a1cfff5b/chienn/model/utils.py">https://github.com/gmum/ChiENN/blob/ee3185b39e8469a8caacf3d6d45a04c4a1cfff5b/chienn/model/utils.py</a>
and serve the purpose of comparing this projects model to a pre-existing model.</p>
<dl class="py function">
<dt class="sig sig-object py" id="ptgnn.model.chienn.utils.build_embedding_layer">
<span class="sig-prename descclassname"><span class="pre">ptgnn.model.chienn.utils.</span></span><span class="sig-name descname"><span class="pre">build_embedding_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ptgnn/model/chienn/utils.html#build_embedding_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ptgnn.model.chienn.utils.build_embedding_layer" title="Link to this definition"></a></dt>
<dd><p>Function to build a pytorch embedding layer from a string that defines which type and if it is a composite type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_dim</strong> (<em>int</em>) – input dimension</p></li>
<li><p><strong>out_dim</strong> (<em>int</em>) – output dimension</p></li>
<li><p><strong>name</strong> (<em>str</em>) – name of the pytorch element(s)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Embedding layer</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-ptgnn.model.chienn">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-ptgnn.model.chienn" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ptgnn.model.html" class="btn btn-neutral float-left" title="ptgnn.model package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ptgnn.model.framework.html" class="btn btn-neutral float-right" title="ptgnn.model.framework package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Johannes P. Urban, B.Sc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>